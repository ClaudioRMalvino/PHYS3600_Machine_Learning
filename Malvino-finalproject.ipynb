{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_validate, KFold, cross_val_predict, GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read in all of the data and set the targets and features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 5)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel_targets= pd.read_csv('GalaxyProperties-targets.csv')\n",
    "print(sel_targets.head(10))\n",
    "sel_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5         6    \\\n",
      "0    0.010532  0.011854  0.011477  0.011186  0.010723  0.007781  0.003281   \n",
      "1    0.012205  0.013479  0.013350  0.013067  0.013404  0.011026  0.005107   \n",
      "2    0.003660  0.004010  0.004001  0.003920  0.004109  0.003515  0.001691   \n",
      "3    0.065447  0.071665  0.071253  0.069657  0.072569  0.061464  0.029246   \n",
      "4    0.143073  0.156413  0.155725  0.152241  0.159254  0.135972  0.065265   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "995  0.084785  0.092999  0.092949  0.091197  0.095809  0.082226  0.039687   \n",
      "996  0.014452  0.015888  0.016062  0.015868  0.017012  0.015016  0.007340   \n",
      "997  0.153889  0.168172  0.167482  0.163732  0.171433  0.146658  0.070557   \n",
      "998  0.025145  0.027639  0.027524  0.026976  0.028090  0.023713  0.011243   \n",
      "999  0.046592  0.051136  0.051223  0.050333  0.053077  0.045830  0.022268   \n",
      "\n",
      "          7         8         9    ...       840       841       842  \\\n",
      "0    0.007836  0.008751  0.012667  ...  0.024035  0.023810  0.024046   \n",
      "1    0.011005  0.012001  0.014975  ...  0.045495  0.044942  0.045321   \n",
      "2    0.003498  0.003792  0.004505  ...  0.016169  0.015951  0.016057   \n",
      "3    0.060936  0.065971  0.078945  ...  0.052733  0.051933  0.052260   \n",
      "4    0.134719  0.145695  0.172647  ...  0.071784  0.070843  0.071313   \n",
      "..        ...       ...       ...  ...       ...       ...       ...   \n",
      "995  0.082044  0.089028  0.105681  ...  0.237033  0.234978  0.237017   \n",
      "996  0.015144  0.016453  0.019114  ...  0.116852  0.117667  0.119247   \n",
      "997  0.145284  0.157084  0.185707  ...  0.077033  0.076005  0.076493   \n",
      "998  0.023641  0.025681  0.031034  ...  0.054181  0.053688  0.054170   \n",
      "999  0.045849  0.049797  0.058873  ...  0.120998  0.121018  0.122442   \n",
      "\n",
      "          843       844       845       846       847       848       849  \n",
      "0    0.023865  0.023751  0.023780  0.023700  0.023532  0.023523  0.023560  \n",
      "1    0.044943  0.044721  0.044843  0.044598  0.043910  0.043594  0.043794  \n",
      "2    0.015907  0.015811  0.015818  0.015722  0.015475  0.015348  0.015374  \n",
      "3    0.051681  0.051270  0.051238  0.050767  0.049791  0.049233  0.049177  \n",
      "4    0.070579  0.070022  0.069911  0.069362  0.068354  0.067859  0.067661  \n",
      "..        ...       ...       ...       ...       ...       ...       ...  \n",
      "995  0.236048  0.235719  0.236943  0.236522  0.234346  0.233746  0.235702  \n",
      "996  0.120329  0.121477  0.123043  0.124556  0.126414  0.128591  0.131057  \n",
      "997  0.075710  0.075119  0.075009  0.074406  0.073292  0.072723  0.072523  \n",
      "998  0.053871  0.053724  0.053934  0.053792  0.053276  0.053137  0.053471  \n",
      "999  0.122760  0.123251  0.124308  0.125061  0.125763  0.127002  0.128654  \n",
      "\n",
      "[1000 rows x 850 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1000, 850)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spectra = pd.read_csv('spectra-feats.csv', header = None, delimiter=\" \")\n",
    "print(spectra)\n",
    "spectra.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(850,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wavelengths = np.loadtxt('Wavelengths.txt')\n",
    "wavelengths.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Organized our features into their own category so that they can be modeled seperatly. I will be focusing on dust and tau for my portion of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1)\n"
     ]
    }
   ],
   "source": [
    "dust = sel_targets[['Dust attenuation value']]\n",
    "age = sel_targets[['Age (Gyr)']]\n",
    "mass_log10  = sel_targets[['Log10(Mass/Mass_Sun)']]\n",
    "tau = sel_targets[['Tau (Gyr)']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Dust}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/claudio/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/claudio/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/claudio/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/claudio/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/claudio/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_validate(RandomForestRegressor(random_state = 10),spectra,dust,cv = KFold(n_splits=5, shuffle=True, random_state=10), \\\n",
    "               return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.853 0.062\n"
     ]
    }
   ],
   "source": [
    "print(np.round(np.mean(scores['test_score']),3), np.round(np.std(scores['test_score']),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.981 0.002\n"
     ]
    }
   ],
   "source": [
    "print(np.round(np.mean(scores['train_score']),3), np.round(np.std(scores['train_score']),3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen above, I decided to utilize RandomForestRegressor just as a baseline to see where we are with our data and how well it can be modeled. I got a training score of 0.981 and a test score of 0.853, which tells me that there is a lot of varience in our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/claudio/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1068: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/claudio/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1068: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/claudio/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1068: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/claudio/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1068: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/claudio/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1068: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8400445460542572"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = cross_val_predict( RandomForestRegressor(random_state = 5), spectra,dust, cv =  KFold(n_splits=5, shuffle=True, random_state=10))\n",
    "metrics.r2_score(dust, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Predictions')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(dust,pred)\n",
    "plt.title('Dust (RandomForestRegressor)')\n",
    "plt.xlabel('True values')\n",
    "plt.ylabel('Predictions')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I then attempted to use the HGB Regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=6, max_iter=20; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=6, max_iter=20; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=6, max_iter=20; total time=   1.0s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=6, max_iter=20; total time=   0.9s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=6, max_iter=20; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=6, max_iter=50; total time=   1.2s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=6, max_iter=50; total time=   1.2s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=6, max_iter=50; total time=   1.4s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=6, max_iter=50; total time=   1.4s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=6, max_iter=50; total time=   1.3s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=6, max_iter=100; total time=   2.0s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=6, max_iter=100; total time=   2.3s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=6, max_iter=100; total time=   2.0s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=6, max_iter=100; total time=   2.6s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=10, max_iter=20; total time=   1.2s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=6, max_iter=100; total time=   1.9s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=10, max_iter=20; total time=   1.2s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=10, max_iter=20; total time=   1.5s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=10, max_iter=20; total time=   1.2s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=10, max_iter=20; total time=   1.3s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=10, max_iter=50; total time=   2.1s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=10, max_iter=50; total time=   2.3s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=10, max_iter=50; total time=   2.5s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=10, max_iter=50; total time=   2.3s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=10, max_iter=50; total time=   2.3s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=10, max_iter=100; total time=   3.6s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=10, max_iter=100; total time=   3.5s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=10, max_iter=100; total time=   4.0s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=None, max_iter=20; total time=   1.4s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=10, max_iter=100; total time=   4.0s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=None, max_iter=20; total time=   1.3s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=None, max_iter=20; total time=   1.7s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=10, max_iter=100; total time=   3.3s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=None, max_iter=20; total time=   1.6s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=None, max_iter=20; total time=   1.2s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=None, max_iter=50; total time=   3.1s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=None, max_iter=50; total time=   3.6s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=None, max_iter=50; total time=   3.7s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=None, max_iter=50; total time=   3.7s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=None, max_iter=50; total time=   3.4s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=None, max_iter=100; total time=   6.9s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=None, max_iter=100; total time=   7.5s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=None, max_iter=100; total time=   8.2s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=6, max_iter=20; total time=   1.5s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=None, max_iter=100; total time=   6.3s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=6, max_iter=20; total time=   1.4s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=6, max_iter=20; total time=   1.3s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=6, max_iter=20; total time=   1.5s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=6, max_iter=20; total time=   1.2s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=6, max_iter=50; total time=   2.4s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=None, max_iter=100; total time=   5.7s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=6, max_iter=50; total time=   2.4s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=6, max_iter=50; total time=   3.2s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=6, max_iter=50; total time=   2.4s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=6, max_iter=50; total time=   2.6s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=6, max_iter=100; total time=   3.5s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=6, max_iter=100; total time=   3.9s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=6, max_iter=100; total time=   3.5s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=10, max_iter=20; total time=   1.9s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=6, max_iter=100; total time=   3.9s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=10, max_iter=20; total time=   1.9s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=6, max_iter=100; total time=   3.8s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=10, max_iter=20; total time=   1.9s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=10, max_iter=20; total time=   1.7s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=10, max_iter=20; total time=   1.9s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=10, max_iter=50; total time=   3.1s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=10, max_iter=50; total time=   3.7s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=10, max_iter=50; total time=   4.0s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=10, max_iter=50; total time=   4.0s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=10, max_iter=50; total time=   4.3s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=10, max_iter=100; total time=   6.0s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=10, max_iter=100; total time=   6.1s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=10, max_iter=100; total time=   6.5s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=None, max_iter=20; total time=   2.1s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=10, max_iter=100; total time=   6.1s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=None, max_iter=20; total time=   1.7s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=None, max_iter=20; total time=   2.1s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=10, max_iter=100; total time=   5.6s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=None, max_iter=20; total time=   1.9s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=None, max_iter=20; total time=   1.6s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=None, max_iter=50; total time=   3.9s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=None, max_iter=50; total time=   3.5s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=None, max_iter=50; total time=   3.7s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=None, max_iter=50; total time=   3.9s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=None, max_iter=50; total time=   3.4s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=None, max_iter=100; total time=   6.8s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=None, max_iter=100; total time=   7.4s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=None, max_iter=100; total time=   7.5s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=6, max_iter=20; total time=   1.1s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=None, max_iter=100; total time=   6.8s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=6, max_iter=20; total time=   1.2s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=6, max_iter=20; total time=   1.0s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=6, max_iter=20; total time=   0.9s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=6, max_iter=20; total time=   0.9s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=6, max_iter=50; total time=   1.4s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=6, max_iter=50; total time=   1.6s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=6, max_iter=50; total time=   1.5s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=6, max_iter=50; total time=   1.5s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=None, max_iter=100; total time=   6.3s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=6, max_iter=50; total time=   1.7s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=6, max_iter=100; total time=   2.1s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=6, max_iter=100; total time=   2.3s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=6, max_iter=100; total time=   2.9s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=6, max_iter=100; total time=   2.5s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=6, max_iter=100; total time=   2.5s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=10, max_iter=20; total time=   1.4s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=10, max_iter=20; total time=   1.4s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=10, max_iter=20; total time=   1.2s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=10, max_iter=20; total time=   1.2s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=10, max_iter=20; total time=   1.3s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=10, max_iter=50; total time=   2.0s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=10, max_iter=50; total time=   2.1s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=10, max_iter=50; total time=   2.2s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=10, max_iter=50; total time=   2.1s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=10, max_iter=50; total time=   2.0s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=10, max_iter=100; total time=   3.7s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=10, max_iter=100; total time=   3.6s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=10, max_iter=100; total time=   4.6s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=10, max_iter=100; total time=   3.2s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=None, max_iter=20; total time=   1.7s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=None, max_iter=20; total time=   2.0s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=None, max_iter=20; total time=   1.8s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=10, max_iter=100; total time=   3.3s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=None, max_iter=20; total time=   1.8s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=None, max_iter=20; total time=   1.7s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=None, max_iter=50; total time=   3.5s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=None, max_iter=50; total time=   3.6s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=None, max_iter=50; total time=   4.4s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=None, max_iter=50; total time=   4.7s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=None, max_iter=50; total time=   4.2s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=None, max_iter=100; total time=   7.6s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=None, max_iter=100; total time=   7.4s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=6, max_iter=20; total time=   1.7s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=None, max_iter=100; total time=   7.8s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=None, max_iter=100; total time=   9.4s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=6, max_iter=20; total time=   1.7s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=6, max_iter=20; total time=   1.3s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=6, max_iter=20; total time=   1.6s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=6, max_iter=20; total time=   1.6s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=None, max_iter=100; total time=   6.5s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=6, max_iter=50; total time=   2.2s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=6, max_iter=50; total time=   2.3s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=6, max_iter=50; total time=   2.1s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=6, max_iter=50; total time=   2.1s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=6, max_iter=50; total time=   2.1s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=6, max_iter=100; total time=   3.1s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=6, max_iter=100; total time=   3.9s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=6, max_iter=100; total time=   3.3s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=6, max_iter=100; total time=   3.0s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=10, max_iter=20; total time=   1.4s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=10, max_iter=20; total time=   1.4s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=6, max_iter=100; total time=   3.2s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=10, max_iter=20; total time=   1.9s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=10, max_iter=20; total time=   1.5s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=10, max_iter=20; total time=   1.6s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=10, max_iter=50; total time=   2.8s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=10, max_iter=50; total time=   2.9s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=10, max_iter=50; total time=   2.8s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=10, max_iter=50; total time=   3.0s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=10, max_iter=50; total time=   2.9s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=10, max_iter=100; total time=   5.4s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=10, max_iter=100; total time=   5.9s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=10, max_iter=100; total time=   4.9s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=10, max_iter=100; total time=   4.7s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=None, max_iter=20; total time=   1.9s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=None, max_iter=20; total time=   1.7s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=None, max_iter=20; total time=   1.9s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=None, max_iter=20; total time=   1.8s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=None, max_iter=20; total time=   1.9s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=10, max_iter=100; total time=   4.8s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=None, max_iter=50; total time=   3.3s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=None, max_iter=50; total time=   3.6s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=None, max_iter=50; total time=   3.8s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=None, max_iter=50; total time=   4.6s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=None, max_iter=50; total time=   3.8s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=None, max_iter=100; total time=   7.2s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=None, max_iter=100; total time=   8.1s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=None, max_iter=100; total time=   7.0s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=6, max_iter=20; total time=   1.2s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=6, max_iter=20; total time=   1.2s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=None, max_iter=100; total time=   6.9s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=6, max_iter=20; total time=   1.0s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=6, max_iter=20; total time=   1.1s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=6, max_iter=20; total time=   1.1s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=6, max_iter=50; total time=   1.4s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=6, max_iter=50; total time=   1.5s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=6, max_iter=50; total time=   1.7s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=6, max_iter=50; total time=   1.4s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=None, max_iter=100; total time=   5.8s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=6, max_iter=50; total time=   1.4s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=6, max_iter=100; total time=   2.3s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=6, max_iter=100; total time=   2.7s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=6, max_iter=100; total time=   2.9s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=6, max_iter=100; total time=   2.2s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=10, max_iter=20; total time=   1.3s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=10, max_iter=20; total time=   1.3s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=10, max_iter=20; total time=   1.2s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=6, max_iter=100; total time=   2.2s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=10, max_iter=20; total time=   1.2s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=10, max_iter=20; total time=   1.2s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=10, max_iter=50; total time=   1.9s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=10, max_iter=50; total time=   2.2s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=10, max_iter=50; total time=   1.8s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=10, max_iter=50; total time=   2.2s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=10, max_iter=50; total time=   2.3s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=10, max_iter=100; total time=   3.3s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=10, max_iter=100; total time=   3.2s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=10, max_iter=100; total time=   3.7s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=10, max_iter=100; total time=   3.6s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=None, max_iter=20; total time=   1.9s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=None, max_iter=20; total time=   2.0s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=10, max_iter=100; total time=   3.1s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=None, max_iter=20; total time=   1.6s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=None, max_iter=20; total time=   1.8s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=None, max_iter=20; total time=   2.1s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=None, max_iter=50; total time=   3.9s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=None, max_iter=50; total time=   4.1s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=None, max_iter=50; total time=   4.4s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=None, max_iter=50; total time=   4.1s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=None, max_iter=50; total time=   4.3s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=None, max_iter=100; total time=   7.0s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=None, max_iter=100; total time=   8.6s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=None, max_iter=100; total time=   8.2s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=6, max_iter=20; total time=   1.4s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=None, max_iter=100; total time=   7.4s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=6, max_iter=20; total time=   1.5s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=6, max_iter=20; total time=   1.3s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=6, max_iter=20; total time=   1.4s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=6, max_iter=20; total time=   1.5s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=None, max_iter=100; total time=   6.8s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=6, max_iter=50; total time=   2.2s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=6, max_iter=50; total time=   2.1s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=6, max_iter=50; total time=   2.1s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=6, max_iter=50; total time=   1.8s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=6, max_iter=50; total time=   2.3s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=6, max_iter=100; total time=   3.1s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=6, max_iter=100; total time=   3.7s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=6, max_iter=100; total time=   2.9s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=6, max_iter=100; total time=   3.1s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=10, max_iter=20; total time=   1.8s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=10, max_iter=20; total time=   1.8s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=6, max_iter=100; total time=   2.8s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=10, max_iter=20; total time=   1.7s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=10, max_iter=20; total time=   1.5s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=10, max_iter=20; total time=   1.6s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=10, max_iter=50; total time=   2.7s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=10, max_iter=50; total time=   2.8s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=10, max_iter=50; total time=   3.0s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=10, max_iter=50; total time=   2.8s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=10, max_iter=50; total time=   3.4s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=10, max_iter=100; total time=   5.2s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=10, max_iter=100; total time=   5.0s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=10, max_iter=100; total time=   5.6s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=10, max_iter=100; total time=   4.5s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=None, max_iter=20; total time=   1.8s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=None, max_iter=20; total time=   1.9s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=None, max_iter=20; total time=   1.7s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=None, max_iter=20; total time=   2.0s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=None, max_iter=20; total time=   1.9s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=10, max_iter=100; total time=   5.1s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=None, max_iter=50; total time=   3.6s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=None, max_iter=50; total time=   3.5s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=None, max_iter=50; total time=   4.2s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=None, max_iter=50; total time=   3.9s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=None, max_iter=50; total time=   3.3s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=None, max_iter=100; total time=   7.1s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=None, max_iter=100; total time=   7.5s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=None, max_iter=100; total time=   7.4s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=None, max_iter=100; total time=   6.6s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=None, max_iter=100; total time=   3.5s\n",
      "Best params, best score: 0.8581 {'learning_rate': 0.5, 'loss': 'squared_error', 'max_depth': 6, 'max_iter': 100}\n"
     ]
    }
   ],
   "source": [
    "parameters = {'max_depth':[6,10,None], 'loss':['squared_error','absolute_error'], \n",
    "              'max_iter':[20,50,100], 'learning_rate': [0.1,0.3,0.5]}\n",
    "nmodels = np.product([len(el) for el in parameters.values()])\n",
    "model = GridSearchCV(HistGradientBoostingRegressor(max_bins = 100), parameters, \n",
    "                     cv = KFold(n_splits=5, shuffle=True, random_state = 5), \\\n",
    "                     verbose = 2, n_jobs = 4, return_train_score=True)\n",
    "model.fit(spectra,dust.values.ravel())\n",
    "\n",
    "print('Best params, best score:', \"{:.4f}\".format(model.best_score_), \\\n",
    "      model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>{'learning_rate': 0.5, 'loss': 'squared_error'...</td>\n",
       "      <td>0.858091</td>\n",
       "      <td>0.050175</td>\n",
       "      <td>0.995115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>{'learning_rate': 0.3, 'loss': 'squared_error'...</td>\n",
       "      <td>0.857545</td>\n",
       "      <td>0.036792</td>\n",
       "      <td>0.987448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'squared_error'...</td>\n",
       "      <td>0.857062</td>\n",
       "      <td>0.046551</td>\n",
       "      <td>0.945880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>{'learning_rate': 0.5, 'loss': 'squared_error'...</td>\n",
       "      <td>0.856736</td>\n",
       "      <td>0.049958</td>\n",
       "      <td>0.983924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>{'learning_rate': 0.3, 'loss': 'squared_error'...</td>\n",
       "      <td>0.855599</td>\n",
       "      <td>0.043880</td>\n",
       "      <td>0.989466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               params  mean_test_score  \\\n",
       "38  {'learning_rate': 0.5, 'loss': 'squared_error'...         0.858091   \n",
       "20  {'learning_rate': 0.3, 'loss': 'squared_error'...         0.857545   \n",
       "2   {'learning_rate': 0.1, 'loss': 'squared_error'...         0.857062   \n",
       "37  {'learning_rate': 0.5, 'loss': 'squared_error'...         0.856736   \n",
       "23  {'learning_rate': 0.3, 'loss': 'squared_error'...         0.855599   \n",
       "\n",
       "    std_test_score  mean_train_score  \n",
       "38        0.050175          0.995115  \n",
       "20        0.036792          0.987448  \n",
       "2         0.046551          0.945880  \n",
       "37        0.049958          0.983924  \n",
       "23        0.043880          0.989466  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hist GBR scores\n",
    "\n",
    "scores = pd.DataFrame(model.cv_results_)\n",
    "scoresCV = scores[['params','mean_test_score','std_test_score','mean_train_score']].sort_values(by = 'mean_test_score', \\\n",
    "                                                    ascending = False)\n",
    "scoresCV.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen from the results above, it did not do much in reducing the variance and appears to have overfitted the data, increasing the variance even further. Therefore, I gave XGB an attempt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[CV] END learning_rate=0.05, max_depth=None, n_estimators=100, objective=reg:squaredlogerror, subsample=0.5; total time=   5.7s\n",
      "[CV] END learning_rate=0.05, max_depth=None, n_estimators=100, objective=reg:squaredlogerror, subsample=0.5; total time=   5.8s\n",
      "[CV] END learning_rate=0.05, max_depth=None, n_estimators=100, objective=reg:squaredlogerror, subsample=0.5; total time=   6.4s\n",
      "[CV] END learning_rate=0.05, max_depth=None, n_estimators=100, objective=reg:squaredlogerror, subsample=0.5; total time=   6.4s\n",
      "[CV] END learning_rate=0.05, max_depth=None, n_estimators=100, objective=reg:squaredlogerror, subsample=0.5; total time=   6.6s\n",
      "[CV] END learning_rate=0.05, max_depth=6, n_estimators=200, objective=reg:squaredlogerror, subsample=0.5; total time=  13.7s\n",
      "[CV] END learning_rate=0.05, max_depth=6, n_estimators=200, objective=reg:squaredlogerror, subsample=0.5; total time=  13.4s\n",
      "[CV] END learning_rate=0.05, max_depth=6, n_estimators=200, objective=reg:squaredlogerror, subsample=0.5; total time=  13.7s\n",
      "[CV] END learning_rate=0.05, max_depth=6, n_estimators=200, objective=reg:squaredlogerror, subsample=0.5; total time=  14.2s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=100, objective=reg:squaredlogerror, subsample=0.5; total time=  10.0s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=100, objective=reg:squaredlogerror, subsample=0.5; total time=  10.7s\n",
      "[CV] END learning_rate=0.05, max_depth=6, n_estimators=200, objective=reg:squaredlogerror, subsample=0.5; total time=  14.2s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=100, objective=reg:squaredlogerror, subsample=0.5; total time=  10.9s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=100, objective=reg:squaredlogerror, subsample=0.5; total time=  11.0s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=100, objective=reg:squaredlogerror, subsample=0.5; total time=  11.4s\n",
      "[CV] END learning_rate=0.1, max_depth=6, n_estimators=200, objective=reg:squaredlogerror, subsample=0.5; total time=  17.6s\n",
      "[CV] END learning_rate=0.1, max_depth=6, n_estimators=200, objective=reg:squaredlogerror, subsample=0.5; total time=  20.0s\n",
      "[CV] END learning_rate=0.1, max_depth=6, n_estimators=200, objective=reg:squaredlogerror, subsample=0.5; total time=  21.3s\n",
      "[CV] END learning_rate=0.1, max_depth=6, n_estimators=200, objective=reg:squaredlogerror, subsample=0.5; total time=  22.0s\n",
      "[CV] END learning_rate=0.02, max_depth=10, n_estimators=100, objective=reg:squaredlogerror, subsample=0.5; total time=  13.5s\n",
      "[CV] END learning_rate=0.1, max_depth=6, n_estimators=200, objective=reg:squaredlogerror, subsample=0.5; total time=  20.9s\n",
      "[CV] END learning_rate=0.02, max_depth=10, n_estimators=100, objective=reg:squaredlogerror, subsample=0.5; total time=  12.7s\n",
      "[CV] END learning_rate=0.02, max_depth=10, n_estimators=100, objective=reg:squaredlogerror, subsample=0.5; total time=  13.7s\n",
      "[CV] END learning_rate=0.02, max_depth=10, n_estimators=100, objective=reg:squaredlogerror, subsample=0.5; total time=  12.4s\n",
      "[CV] END learning_rate=0.02, max_depth=10, n_estimators=100, objective=reg:squaredlogerror, subsample=0.5; total time=  14.3s\n",
      "[CV] END learning_rate=0.1, max_depth=None, n_estimators=200, objective=reg:squaredlogerror, subsample=1; total time=  34.9s\n",
      "[CV] END learning_rate=0.1, max_depth=None, n_estimators=200, objective=reg:squaredlogerror, subsample=1; total time=  34.7s\n",
      "[CV] END learning_rate=0.1, max_depth=None, n_estimators=200, objective=reg:squaredlogerror, subsample=1; total time=  33.6s\n",
      "[CV] END learning_rate=0.1, max_depth=None, n_estimators=200, objective=reg:squaredlogerror, subsample=1; total time=  35.9s\n",
      "[CV] END learning_rate=0.1, max_depth=None, n_estimators=200, objective=reg:squaredlogerror, subsample=1; total time=  33.8s\n",
      "[CV] END learning_rate=0.3, max_depth=10, n_estimators=500, objective=reg:squaredlogerror, subsample=1; total time= 1.1min\n",
      "[CV] END learning_rate=0.3, max_depth=10, n_estimators=500, objective=reg:squaredlogerror, subsample=1; total time= 1.1min\n",
      "[CV] END learning_rate=0.3, max_depth=10, n_estimators=500, objective=reg:squaredlogerror, subsample=1; total time= 1.1min\n",
      "[CV] END learning_rate=0.3, max_depth=10, n_estimators=500, objective=reg:squaredlogerror, subsample=1; total time=  50.1s\n",
      "[CV] END learning_rate=0.02, max_depth=10, n_estimators=100, objective=reg:squarederror, subsample=0.5; total time=   9.5s\n",
      "[CV] END learning_rate=0.02, max_depth=10, n_estimators=100, objective=reg:squarederror, subsample=0.5; total time=   9.4s\n",
      "[CV] END learning_rate=0.02, max_depth=10, n_estimators=100, objective=reg:squarederror, subsample=0.5; total time=  12.8s\n",
      "[CV] END learning_rate=0.02, max_depth=10, n_estimators=100, objective=reg:squarederror, subsample=0.5; total time=  13.6s\n",
      "[CV] END learning_rate=0.02, max_depth=10, n_estimators=100, objective=reg:squarederror, subsample=0.5; total time=  13.7s\n",
      "[CV] END learning_rate=0.05, max_depth=6, n_estimators=100, objective=reg:squaredlogerror, subsample=0.5; total time=  11.5s\n",
      "[CV] END learning_rate=0.05, max_depth=6, n_estimators=100, objective=reg:squaredlogerror, subsample=0.5; total time=  10.7s\n",
      "[CV] END learning_rate=0.05, max_depth=6, n_estimators=100, objective=reg:squaredlogerror, subsample=0.5; total time=  10.7s\n",
      "[CV] END learning_rate=0.05, max_depth=6, n_estimators=100, objective=reg:squaredlogerror, subsample=0.5; total time=  11.1s\n",
      "[CV] END learning_rate=0.05, max_depth=6, n_estimators=100, objective=reg:squaredlogerror, subsample=0.5; total time=  10.2s\n",
      "[CV] END learning_rate=0.3, max_depth=10, n_estimators=500, objective=reg:squaredlogerror, subsample=1; total time= 1.1min\n",
      "[CV] END learning_rate=0.1, max_depth=6, n_estimators=500, objective=reg:squaredlogerror, subsample=1; total time= 1.4min\n",
      "[CV] END learning_rate=0.1, max_depth=6, n_estimators=500, objective=reg:squaredlogerror, subsample=1; total time= 1.4min\n",
      "[CV] END learning_rate=0.1, max_depth=6, n_estimators=500, objective=reg:squaredlogerror, subsample=1; total time= 1.4min\n",
      "[CV] END learning_rate=0.1, max_depth=6, n_estimators=500, objective=reg:squaredlogerror, subsample=1; total time= 1.4min\n",
      "[CV] END learning_rate=0.02, max_depth=6, n_estimators=200, objective=reg:squaredlogerror, subsample=0.5; total time=  21.0s\n",
      "[CV] END learning_rate=0.02, max_depth=6, n_estimators=200, objective=reg:squaredlogerror, subsample=0.5; total time=  21.4s\n",
      "[CV] END learning_rate=0.02, max_depth=6, n_estimators=200, objective=reg:squaredlogerror, subsample=0.5; total time=  18.3s\n",
      "[CV] END learning_rate=0.02, max_depth=6, n_estimators=200, objective=reg:squaredlogerror, subsample=0.5; total time=  18.5s\n",
      "[CV] END learning_rate=0.02, max_depth=6, n_estimators=200, objective=reg:squaredlogerror, subsample=0.5; total time=  18.2s\n",
      "[CV] END learning_rate=0.3, max_depth=10, n_estimators=100, objective=reg:squaredlogerror, subsample=0.5; total time=  17.7s\n",
      "[CV] END learning_rate=0.3, max_depth=10, n_estimators=100, objective=reg:squaredlogerror, subsample=0.5; total time=  18.1s\n",
      "[CV] END learning_rate=0.3, max_depth=10, n_estimators=100, objective=reg:squaredlogerror, subsample=0.5; total time=  17.0s\n",
      "[CV] END learning_rate=0.3, max_depth=10, n_estimators=100, objective=reg:squaredlogerror, subsample=0.5; total time=  16.3s\n",
      "[CV] END learning_rate=0.3, max_depth=10, n_estimators=100, objective=reg:squaredlogerror, subsample=0.5; total time=  15.9s\n",
      "[CV] END learning_rate=0.1, max_depth=6, n_estimators=500, objective=reg:squaredlogerror, subsample=1; total time= 1.4min\n",
      "[CV] END learning_rate=0.05, max_depth=6, n_estimators=500, objective=reg:squaredlogerror, subsample=1; total time= 1.4min\n",
      "[CV] END learning_rate=0.05, max_depth=6, n_estimators=500, objective=reg:squaredlogerror, subsample=1; total time= 1.3min\n",
      "[CV] END learning_rate=0.05, max_depth=6, n_estimators=500, objective=reg:squaredlogerror, subsample=1; total time= 1.3min\n",
      "[CV] END learning_rate=0.05, max_depth=6, n_estimators=500, objective=reg:squaredlogerror, subsample=1; total time= 1.3min\n",
      "[CV] END learning_rate=0.02, max_depth=6, n_estimators=500, objective=reg:squarederror, subsample=0.5; total time=  52.0s\n",
      "[CV] END learning_rate=0.02, max_depth=6, n_estimators=500, objective=reg:squarederror, subsample=0.5; total time=  54.4s\n",
      "[CV] END learning_rate=0.02, max_depth=6, n_estimators=500, objective=reg:squarederror, subsample=0.5; total time=  52.7s\n",
      "[CV] END learning_rate=0.05, max_depth=6, n_estimators=500, objective=reg:squaredlogerror, subsample=1; total time= 1.4min\n",
      "[CV] END learning_rate=0.3, max_depth=6, n_estimators=100, objective=reg:squarederror, subsample=1; total time=  17.1s\n",
      "[CV] END learning_rate=0.3, max_depth=6, n_estimators=100, objective=reg:squarederror, subsample=1; total time=  12.2s\n",
      "[CV] END learning_rate=0.3, max_depth=6, n_estimators=100, objective=reg:squarederror, subsample=1; total time=  13.2s\n",
      "[CV] END learning_rate=0.3, max_depth=6, n_estimators=100, objective=reg:squarederror, subsample=1; total time=  15.2s\n",
      "[CV] END learning_rate=0.3, max_depth=6, n_estimators=100, objective=reg:squarederror, subsample=1; total time=  16.2s\n",
      "[CV] END learning_rate=0.02, max_depth=6, n_estimators=500, objective=reg:squarederror, subsample=0.5; total time=  52.2s\n",
      "[CV] END learning_rate=0.02, max_depth=6, n_estimators=500, objective=reg:squarederror, subsample=0.5; total time=  52.3s\n",
      "[CV] END learning_rate=0.02, max_depth=10, n_estimators=200, objective=reg:squaredlogerror, subsample=0.5; total time=  27.7s\n",
      "[CV] END learning_rate=0.02, max_depth=10, n_estimators=200, objective=reg:squaredlogerror, subsample=0.5; total time=  25.5s\n",
      "[CV] END learning_rate=0.02, max_depth=10, n_estimators=200, objective=reg:squaredlogerror, subsample=0.5; total time=  27.4s\n",
      "[CV] END learning_rate=0.02, max_depth=10, n_estimators=200, objective=reg:squaredlogerror, subsample=0.5; total time=  27.8s\n",
      "[CV] END learning_rate=0.02, max_depth=10, n_estimators=200, objective=reg:squaredlogerror, subsample=0.5; total time=  29.2s\n",
      "[CV] END learning_rate=0.05, max_depth=None, n_estimators=500, objective=reg:squarederror, subsample=1; total time= 1.4min\n",
      "[CV] END learning_rate=0.05, max_depth=None, n_estimators=500, objective=reg:squarederror, subsample=1; total time= 1.4min\n",
      "[CV] END learning_rate=0.05, max_depth=None, n_estimators=500, objective=reg:squarederror, subsample=1; total time= 1.5min\n",
      "[CV] END learning_rate=0.05, max_depth=None, n_estimators=500, objective=reg:squarederror, subsample=1; total time= 1.3min\n",
      "[CV] END learning_rate=0.3, max_depth=10, n_estimators=500, objective=reg:squaredlogerror, subsample=0.5; total time= 1.1min\n",
      "[CV] END learning_rate=0.3, max_depth=10, n_estimators=500, objective=reg:squaredlogerror, subsample=0.5; total time= 1.1min\n",
      "[CV] END learning_rate=0.05, max_depth=None, n_estimators=500, objective=reg:squarederror, subsample=1; total time= 1.4min\n",
      "[CV] END learning_rate=0.3, max_depth=10, n_estimators=500, objective=reg:squaredlogerror, subsample=0.5; total time= 1.1min\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=50, objective=reg:squaredlogerror, subsample=0.5; total time=   6.6s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=50, objective=reg:squaredlogerror, subsample=0.5; total time=   5.4s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=50, objective=reg:squaredlogerror, subsample=0.5; total time=   4.7s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=50, objective=reg:squaredlogerror, subsample=0.5; total time=   4.5s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=50, objective=reg:squaredlogerror, subsample=0.5; total time=   4.4s\n",
      "[CV] END learning_rate=0.3, max_depth=10, n_estimators=500, objective=reg:squaredlogerror, subsample=0.5; total time= 1.0min\n",
      "[CV] END learning_rate=0.3, max_depth=10, n_estimators=500, objective=reg:squaredlogerror, subsample=0.5; total time= 1.1min\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=500, objective=reg:squaredlogerror, subsample=0.5; total time= 1.4min\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=500, objective=reg:squaredlogerror, subsample=0.5; total time= 1.4min\n",
      "[CV] END learning_rate=0.1, max_depth=None, n_estimators=100, objective=reg:squarederror, subsample=1; total time=  17.3s\n",
      "[CV] END learning_rate=0.1, max_depth=None, n_estimators=100, objective=reg:squarederror, subsample=1; total time=  15.8s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=500, objective=reg:squaredlogerror, subsample=0.5; total time= 1.4min\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=500, objective=reg:squaredlogerror, subsample=0.5; total time= 1.3min\n",
      "[CV] END learning_rate=0.1, max_depth=None, n_estimators=100, objective=reg:squarederror, subsample=1; total time=  15.1s\n",
      "[CV] END learning_rate=0.1, max_depth=None, n_estimators=100, objective=reg:squarederror, subsample=1; total time=  16.6s\n",
      "[CV] END learning_rate=0.1, max_depth=None, n_estimators=100, objective=reg:squarederror, subsample=1; total time=  17.3s\n",
      "[CV] END learning_rate=0.1, max_depth=6, n_estimators=100, objective=reg:squaredlogerror, subsample=1; total time=  16.9s\n",
      "[CV] END learning_rate=0.1, max_depth=6, n_estimators=100, objective=reg:squaredlogerror, subsample=1; total time=  17.2s\n",
      "[CV] END learning_rate=0.1, max_depth=6, n_estimators=100, objective=reg:squaredlogerror, subsample=1; total time=  16.4s\n",
      "[CV] END learning_rate=0.1, max_depth=6, n_estimators=100, objective=reg:squaredlogerror, subsample=1; total time=  16.6s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=500, objective=reg:squaredlogerror, subsample=0.5; total time= 1.4min\n",
      "[CV] END learning_rate=0.1, max_depth=6, n_estimators=100, objective=reg:squaredlogerror, subsample=1; total time=  17.3s\n",
      "[CV] END learning_rate=0.02, max_depth=10, n_estimators=500, objective=reg:squaredlogerror, subsample=0.5; total time= 1.2min\n",
      "[CV] END learning_rate=0.02, max_depth=10, n_estimators=500, objective=reg:squaredlogerror, subsample=0.5; total time= 1.2min\n",
      "[CV] END learning_rate=0.02, max_depth=10, n_estimators=500, objective=reg:squaredlogerror, subsample=0.5; total time= 1.2min\n",
      "[CV] END learning_rate=0.02, max_depth=10, n_estimators=500, objective=reg:squaredlogerror, subsample=0.5; total time= 1.3min\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=200, objective=reg:squaredlogerror, subsample=1; total time=  54.2s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=200, objective=reg:squaredlogerror, subsample=1; total time=  54.3s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=200, objective=reg:squaredlogerror, subsample=1; total time=  51.6s\n",
      "[CV] END learning_rate=0.02, max_depth=10, n_estimators=500, objective=reg:squaredlogerror, subsample=0.5; total time= 1.3min\n",
      "[CV] END learning_rate=0.3, max_depth=6, n_estimators=200, objective=reg:squarederror, subsample=0.5; total time=  21.7s\n",
      "[CV] END learning_rate=0.3, max_depth=6, n_estimators=200, objective=reg:squarederror, subsample=0.5; total time=  21.0s\n",
      "[CV] END learning_rate=0.3, max_depth=6, n_estimators=200, objective=reg:squarederror, subsample=0.5; total time=  16.2s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=200, objective=reg:squaredlogerror, subsample=1; total time=  46.2s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=200, objective=reg:squaredlogerror, subsample=1; total time=  47.8s\n",
      "[CV] END learning_rate=0.3, max_depth=6, n_estimators=200, objective=reg:squarederror, subsample=0.5; total time=  15.3s\n",
      "[CV] END learning_rate=0.3, max_depth=6, n_estimators=200, objective=reg:squarederror, subsample=0.5; total time=  20.0s\n",
      "[CV] END learning_rate=0.1, max_depth=6, n_estimators=500, objective=reg:squarederror, subsample=0.5; total time=  54.5s\n",
      "[CV] END learning_rate=0.1, max_depth=6, n_estimators=500, objective=reg:squarederror, subsample=0.5; total time=  52.4s\n",
      "[CV] END learning_rate=0.1, max_depth=6, n_estimators=500, objective=reg:squarederror, subsample=0.5; total time=  54.4s\n",
      "[CV] END learning_rate=0.3, max_depth=6, n_estimators=50, objective=reg:squarederror, subsample=1; total time=   9.3s\n",
      "[CV] END learning_rate=0.3, max_depth=6, n_estimators=50, objective=reg:squarederror, subsample=1; total time=   8.4s\n",
      "[CV] END learning_rate=0.1, max_depth=6, n_estimators=500, objective=reg:squarederror, subsample=0.5; total time=  54.2s\n",
      "[CV] END learning_rate=0.3, max_depth=6, n_estimators=50, objective=reg:squarederror, subsample=1; total time=   9.5s\n",
      "[CV] END learning_rate=0.3, max_depth=6, n_estimators=50, objective=reg:squarederror, subsample=1; total time=   9.0s\n",
      "[CV] END learning_rate=0.3, max_depth=6, n_estimators=50, objective=reg:squarederror, subsample=1; total time=   9.4s\n",
      "[CV] END learning_rate=0.02, max_depth=None, n_estimators=200, objective=reg:squarederror, subsample=0.5; total time=  21.7s\n",
      "[CV] END learning_rate=0.02, max_depth=None, n_estimators=200, objective=reg:squarederror, subsample=0.5; total time=  20.8s\n",
      "[CV] END learning_rate=0.02, max_depth=None, n_estimators=200, objective=reg:squarederror, subsample=0.5; total time=  19.1s\n",
      "[CV] END learning_rate=0.1, max_depth=6, n_estimators=500, objective=reg:squarederror, subsample=0.5; total time=  51.5s\n",
      "[CV] END learning_rate=0.1, max_depth=None, n_estimators=100, objective=reg:squarederror, subsample=0.5; total time=  10.9s\n",
      "[CV] END learning_rate=0.02, max_depth=None, n_estimators=200, objective=reg:squarederror, subsample=0.5; total time=  19.1s\n",
      "[CV] END learning_rate=0.1, max_depth=None, n_estimators=100, objective=reg:squarederror, subsample=0.5; total time=  11.2s\n",
      "[CV] END learning_rate=0.02, max_depth=None, n_estimators=200, objective=reg:squarederror, subsample=0.5; total time=  20.4s\n",
      "[CV] END learning_rate=0.1, max_depth=None, n_estimators=100, objective=reg:squarederror, subsample=0.5; total time=  11.7s\n",
      "[CV] END learning_rate=0.1, max_depth=None, n_estimators=100, objective=reg:squarederror, subsample=0.5; total time=  11.2s\n",
      "[CV] END learning_rate=0.1, max_depth=None, n_estimators=100, objective=reg:squarederror, subsample=0.5; total time=  10.9s\n",
      "[CV] END learning_rate=0.02, max_depth=10, n_estimators=50, objective=reg:squaredlogerror, subsample=1; total time=  10.8s\n",
      "[CV] END learning_rate=0.02, max_depth=10, n_estimators=50, objective=reg:squaredlogerror, subsample=1; total time=  10.4s\n",
      "[CV] END learning_rate=0.02, max_depth=10, n_estimators=50, objective=reg:squaredlogerror, subsample=1; total time=  10.4s\n",
      "[CV] END learning_rate=0.02, max_depth=10, n_estimators=50, objective=reg:squaredlogerror, subsample=1; total time=   9.6s\n",
      "[CV] END learning_rate=0.02, max_depth=10, n_estimators=50, objective=reg:squaredlogerror, subsample=1; total time=   9.0s\n",
      "Best params, best score: 0.9155 {'subsample': 0.5, 'objective': 'reg:squarederror', 'n_estimators': 500, 'max_depth': 6, 'learning_rate': 0.02}\n"
     ]
    }
   ],
   "source": [
    "parameters = {'max_depth':[6,10,None], 'n_estimators':[50, 100, 200,500], \n",
    "              'learning_rate': [0.02,0.05,0.1,0.3], 'objective':['reg:squarederror',\n",
    "                'reg:squaredlogerror'], 'subsample':[0.5,1]}\n",
    "\n",
    "nmodels = np.product([len(el) for el in parameters.values()])\n",
    "model = RandomizedSearchCV(xgb.XGBRegressor(), parameters, cv = KFold(n_splits=5, shuffle=True), \\\n",
    "                     verbose = 2, n_jobs = 4, return_train_score=True, n_iter = 30)\n",
    "model.fit(spectra,dust.values.ravel())\n",
    "\n",
    "print('Best params, best score:', \"{:.4f}\".format(model.best_score_), \\\n",
    "      model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{'subsample': 0.5, 'objective': 'reg:squareder...</td>\n",
       "      <td>0.915489</td>\n",
       "      <td>0.039966</td>\n",
       "      <td>0.998310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>{'subsample': 0.5, 'objective': 'reg:squareder...</td>\n",
       "      <td>0.903994</td>\n",
       "      <td>0.035538</td>\n",
       "      <td>0.999998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>{'subsample': 0.5, 'objective': 'reg:squareder...</td>\n",
       "      <td>0.903638</td>\n",
       "      <td>0.039948</td>\n",
       "      <td>0.999998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>{'subsample': 0.5, 'objective': 'reg:squareder...</td>\n",
       "      <td>0.899499</td>\n",
       "      <td>0.034699</td>\n",
       "      <td>0.997728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>{'subsample': 0.5, 'objective': 'reg:squareder...</td>\n",
       "      <td>0.894483</td>\n",
       "      <td>0.038531</td>\n",
       "      <td>0.982112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               params  mean_test_score  \\\n",
       "13  {'subsample': 0.5, 'objective': 'reg:squareder...         0.915489   \n",
       "25  {'subsample': 0.5, 'objective': 'reg:squareder...         0.903994   \n",
       "24  {'subsample': 0.5, 'objective': 'reg:squareder...         0.903638   \n",
       "28  {'subsample': 0.5, 'objective': 'reg:squareder...         0.899499   \n",
       "27  {'subsample': 0.5, 'objective': 'reg:squareder...         0.894483   \n",
       "\n",
       "    std_test_score  mean_train_score  \n",
       "13        0.039966          0.998310  \n",
       "25        0.035538          0.999998  \n",
       "24        0.039948          0.999998  \n",
       "28        0.034699          0.997728  \n",
       "27        0.038531          0.982112  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#xgb.XGBRegressor scores\n",
    "\n",
    "scores = pd.DataFrame(model.cv_results_)\n",
    "scoresCV = scores[['params','mean_test_score','std_test_score','mean_train_score']].sort_values(by = 'mean_test_score', \\\n",
    "                                                    ascending = False)\n",
    "scoresCV.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizing XGB with RandomizedSearchCV took about 17 minutes to run on my machine, but produced, to my mind, decent scores. I believe that a runtime of ~ 17 minutes is not ideal, but because I had the time to wait and see how good the cores could be, it turned out in my favor. I could reduce the amount of time it takes to run by reducing the size of the features and target, but that will introduce some bias to the system and could also alter the scores negatively, making me believe that this model is not the best one when it could very well be. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Tau}$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After talking amongst the class and with Professor Maller it became apparent that some form of transformation needed to be done to the data, therefore I took the log10 of tau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tau (Gyr)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.481020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.059753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.105160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.615130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.291849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.315953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>-1.201727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>-0.036853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>-0.773986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.547033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Tau (Gyr)\n",
       "0    -1.481020\n",
       "1    -1.059753\n",
       "2     0.105160\n",
       "3    -0.615130\n",
       "4    -0.291849\n",
       "..         ...\n",
       "995   0.315953\n",
       "996  -1.201727\n",
       "997  -0.036853\n",
       "998  -0.773986\n",
       "999   0.547033\n",
       "\n",
       "[1000 rows x 1 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_tau = np.log10(tau)\n",
    "log_tau"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I utilized Random Forest Regressor just as a baseline, to see where things stand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/claudio/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/claudio/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/claudio/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/claudio/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/claudio/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_validate(RandomForestRegressor(random_state = 20),spectra,log_tau,cv = KFold(n_splits=5, shuffle=True, random_state=10), \\\n",
    "               return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.543 0.048\n"
     ]
    }
   ],
   "source": [
    "print(np.round(np.mean(scores['test_score']),3), np.round(np.std(scores['test_score']),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.939 0.002\n"
     ]
    }
   ],
   "source": [
    "print(np.round(np.mean(scores['train_score']),3), np.round(np.std(scores['train_score']),3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, the scores produced were not good at all, therefore I decided to scale the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "standardized_features = scaler.fit_transform(spectra)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 400 )\n",
    "reduced_spectra= pca.fit_transform(standardized_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[CV] END learning_rate=0.02, max_depth=None, n_estimators=50, objective=reg:squarederror, subsample=0.5; total time=   1.2s\n",
      "[CV] END learning_rate=0.02, max_depth=None, n_estimators=50, objective=reg:squarederror, subsample=0.5; total time=   1.4s\n",
      "[CV] END learning_rate=0.05, max_depth=6, n_estimators=100, objective=reg:squaredlogerror, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.05, max_depth=6, n_estimators=100, objective=reg:squaredlogerror, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.05, max_depth=6, n_estimators=100, objective=reg:squaredlogerror, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.05, max_depth=6, n_estimators=100, objective=reg:squaredlogerror, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.05, max_depth=6, n_estimators=100, objective=reg:squaredlogerror, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.02, max_depth=10, n_estimators=50, objective=reg:squaredlogerror, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.02, max_depth=10, n_estimators=50, objective=reg:squaredlogerror, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.02, max_depth=10, n_estimators=50, objective=reg:squaredlogerror, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.02, max_depth=10, n_estimators=50, objective=reg:squaredlogerror, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.02, max_depth=10, n_estimators=50, objective=reg:squaredlogerror, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.3, max_depth=6, n_estimators=50, objective=reg:squaredlogerror, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.3, max_depth=6, n_estimators=50, objective=reg:squaredlogerror, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.02, max_depth=None, n_estimators=50, objective=reg:squarederror, subsample=0.5; total time=   1.4s\n",
      "[CV] END learning_rate=0.3, max_depth=6, n_estimators=50, objective=reg:squaredlogerror, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.3, max_depth=6, n_estimators=50, objective=reg:squaredlogerror, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.3, max_depth=6, n_estimators=50, objective=reg:squaredlogerror, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.02, max_depth=6, n_estimators=200, objective=reg:squaredlogerror, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.02, max_depth=6, n_estimators=200, objective=reg:squaredlogerror, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.02, max_depth=6, n_estimators=200, objective=reg:squaredlogerror, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.02, max_depth=6, n_estimators=200, objective=reg:squaredlogerror, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.02, max_depth=6, n_estimators=200, objective=reg:squaredlogerror, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.02, max_depth=None, n_estimators=50, objective=reg:squarederror, subsample=0.5; total time=   1.5s\n",
      "[CV] END learning_rate=0.02, max_depth=None, n_estimators=50, objective=reg:squarederror, subsample=0.5; total time=   1.4s\n",
      "[CV] END learning_rate=0.3, max_depth=10, n_estimators=200, objective=reg:squarederror, subsample=0.5; total time=   5.4s\n",
      "[CV] END learning_rate=0.3, max_depth=10, n_estimators=200, objective=reg:squarederror, subsample=0.5; total time=   5.7s\n",
      "[CV] END learning_rate=0.3, max_depth=10, n_estimators=200, objective=reg:squarederror, subsample=0.5; total time=   5.8s\n",
      "[CV] END learning_rate=0.3, max_depth=10, n_estimators=200, objective=reg:squarederror, subsample=0.5; total time=   5.9s\n",
      "[CV] END learning_rate=0.1, max_depth=None, n_estimators=50, objective=reg:squarederror, subsample=1; total time=   2.4s\n",
      "[CV] END learning_rate=0.1, max_depth=None, n_estimators=50, objective=reg:squarederror, subsample=1; total time=   2.6s\n",
      "[CV] END learning_rate=0.02, max_depth=None, n_estimators=200, objective=reg:squaredlogerror, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.02, max_depth=None, n_estimators=200, objective=reg:squaredlogerror, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.02, max_depth=None, n_estimators=200, objective=reg:squaredlogerror, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.02, max_depth=None, n_estimators=200, objective=reg:squaredlogerror, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, max_depth=None, n_estimators=50, objective=reg:squarederror, subsample=1; total time=   2.7s\n",
      "[CV] END learning_rate=0.1, max_depth=None, n_estimators=50, objective=reg:squarederror, subsample=1; total time=   2.6s\n",
      "[CV] END learning_rate=0.02, max_depth=None, n_estimators=200, objective=reg:squaredlogerror, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.3, max_depth=10, n_estimators=200, objective=reg:squarederror, subsample=0.5; total time=   5.8s\n",
      "[CV] END learning_rate=0.3, max_depth=None, n_estimators=100, objective=reg:squarederror, subsample=0.5; total time=   3.5s\n",
      "[CV] END learning_rate=0.1, max_depth=None, n_estimators=50, objective=reg:squarederror, subsample=1; total time=   2.6s\n",
      "[CV] END learning_rate=0.3, max_depth=6, n_estimators=50, objective=reg:squaredlogerror, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.3, max_depth=6, n_estimators=50, objective=reg:squaredlogerror, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.3, max_depth=6, n_estimators=50, objective=reg:squaredlogerror, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.3, max_depth=6, n_estimators=50, objective=reg:squaredlogerror, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.3, max_depth=None, n_estimators=100, objective=reg:squarederror, subsample=0.5; total time=   3.6s\n",
      "[CV] END learning_rate=0.3, max_depth=None, n_estimators=100, objective=reg:squarederror, subsample=0.5; total time=   3.5s\n",
      "[CV] END learning_rate=0.3, max_depth=6, n_estimators=50, objective=reg:squaredlogerror, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.3, max_depth=None, n_estimators=100, objective=reg:squarederror, subsample=0.5; total time=   3.8s\n",
      "[CV] END learning_rate=0.3, max_depth=None, n_estimators=100, objective=reg:squarederror, subsample=0.5; total time=   3.6s\n",
      "[CV] END learning_rate=0.02, max_depth=None, n_estimators=500, objective=reg:squarederror, subsample=0.5; total time=  17.6s\n",
      "[CV] END learning_rate=0.02, max_depth=None, n_estimators=500, objective=reg:squarederror, subsample=0.5; total time=  18.2s\n",
      "[CV] END learning_rate=0.05, max_depth=None, n_estimators=500, objective=reg:squaredlogerror, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.05, max_depth=None, n_estimators=500, objective=reg:squaredlogerror, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.05, max_depth=None, n_estimators=500, objective=reg:squaredlogerror, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.05, max_depth=None, n_estimators=500, objective=reg:squaredlogerror, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.05, max_depth=None, n_estimators=500, objective=reg:squaredlogerror, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.02, max_depth=None, n_estimators=500, objective=reg:squaredlogerror, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.02, max_depth=None, n_estimators=500, objective=reg:squaredlogerror, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.02, max_depth=None, n_estimators=500, objective=reg:squaredlogerror, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.02, max_depth=None, n_estimators=500, objective=reg:squaredlogerror, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.02, max_depth=None, n_estimators=500, objective=reg:squaredlogerror, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.02, max_depth=None, n_estimators=500, objective=reg:squarederror, subsample=0.5; total time=  17.7s\n",
      "[CV] END learning_rate=0.02, max_depth=None, n_estimators=500, objective=reg:squarederror, subsample=0.5; total time=  17.8s\n",
      "[CV] END learning_rate=0.02, max_depth=10, n_estimators=200, objective=reg:squarederror, subsample=0.5; total time=   9.9s\n",
      "[CV] END learning_rate=0.02, max_depth=10, n_estimators=200, objective=reg:squarederror, subsample=0.5; total time=   9.6s\n",
      "[CV] END learning_rate=0.02, max_depth=10, n_estimators=200, objective=reg:squarederror, subsample=0.5; total time=  10.0s\n",
      "[CV] END learning_rate=0.1, max_depth=6, n_estimators=200, objective=reg:squaredlogerror, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, max_depth=6, n_estimators=200, objective=reg:squaredlogerror, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, max_depth=6, n_estimators=200, objective=reg:squaredlogerror, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, max_depth=6, n_estimators=200, objective=reg:squaredlogerror, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, max_depth=6, n_estimators=200, objective=reg:squaredlogerror, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.02, max_depth=None, n_estimators=500, objective=reg:squarederror, subsample=0.5; total time=  18.5s\n",
      "[CV] END learning_rate=0.1, max_depth=None, n_estimators=100, objective=reg:squarederror, subsample=1; total time=   5.7s\n",
      "[CV] END learning_rate=0.02, max_depth=10, n_estimators=200, objective=reg:squarederror, subsample=0.5; total time=   9.8s\n",
      "[CV] END learning_rate=0.02, max_depth=10, n_estimators=200, objective=reg:squarederror, subsample=0.5; total time=   9.8s\n",
      "[CV] END learning_rate=0.1, max_depth=None, n_estimators=100, objective=reg:squarederror, subsample=1; total time=   6.4s\n",
      "[CV] END learning_rate=0.1, max_depth=None, n_estimators=100, objective=reg:squarederror, subsample=1; total time=   5.9s\n",
      "[CV] END learning_rate=0.1, max_depth=None, n_estimators=100, objective=reg:squarederror, subsample=1; total time=   6.1s\n",
      "[CV] END learning_rate=0.1, max_depth=None, n_estimators=100, objective=reg:squarederror, subsample=1; total time=   6.1s\n",
      "[CV] END learning_rate=0.02, max_depth=None, n_estimators=100, objective=reg:squarederror, subsample=1; total time=   5.9s\n",
      "[CV] END learning_rate=0.02, max_depth=None, n_estimators=100, objective=reg:squarederror, subsample=1; total time=   7.4s\n",
      "[CV] END learning_rate=0.1, max_depth=None, n_estimators=500, objective=reg:squaredlogerror, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, max_depth=None, n_estimators=500, objective=reg:squaredlogerror, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, max_depth=None, n_estimators=500, objective=reg:squaredlogerror, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, max_depth=None, n_estimators=500, objective=reg:squaredlogerror, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, max_depth=None, n_estimators=500, objective=reg:squaredlogerror, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.02, max_depth=None, n_estimators=100, objective=reg:squarederror, subsample=1; total time=   7.3s\n",
      "[CV] END learning_rate=0.02, max_depth=None, n_estimators=100, objective=reg:squarederror, subsample=1; total time=   7.9s\n",
      "[CV] END learning_rate=0.02, max_depth=None, n_estimators=100, objective=reg:squarederror, subsample=1; total time=   8.0s\n",
      "[CV] END learning_rate=0.05, max_depth=6, n_estimators=500, objective=reg:squarederror, subsample=0.5; total time=  25.6s\n",
      "[CV] END learning_rate=0.05, max_depth=6, n_estimators=500, objective=reg:squarederror, subsample=0.5; total time=  26.0s\n",
      "[CV] END learning_rate=0.05, max_depth=6, n_estimators=500, objective=reg:squarederror, subsample=0.5; total time=  27.3s\n",
      "[CV] END learning_rate=0.05, max_depth=6, n_estimators=500, objective=reg:squarederror, subsample=0.5; total time=  26.6s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=200, objective=reg:squarederror, subsample=1; total time=  24.2s\n",
      "[CV] END learning_rate=0.05, max_depth=6, n_estimators=500, objective=reg:squarederror, subsample=0.5; total time=  28.2s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=200, objective=reg:squarederror, subsample=1; total time=  23.7s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=200, objective=reg:squarederror, subsample=1; total time=  24.9s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=200, objective=reg:squarederror, subsample=1; total time=  28.3s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=200, objective=reg:squarederror, subsample=1; total time=  28.8s\n",
      "[CV] END learning_rate=0.02, max_depth=6, n_estimators=500, objective=reg:squarederror, subsample=0.5; total time=  31.0s\n",
      "[CV] END learning_rate=0.02, max_depth=6, n_estimators=500, objective=reg:squarederror, subsample=0.5; total time=  32.3s\n",
      "[CV] END learning_rate=0.1, max_depth=6, n_estimators=100, objective=reg:squarederror, subsample=1; total time=   8.4s\n",
      "[CV] END learning_rate=0.1, max_depth=6, n_estimators=100, objective=reg:squarederror, subsample=1; total time=   8.1s\n",
      "[CV] END learning_rate=0.02, max_depth=6, n_estimators=500, objective=reg:squarederror, subsample=0.5; total time=  27.2s\n",
      "[CV] END learning_rate=0.02, max_depth=6, n_estimators=500, objective=reg:squarederror, subsample=0.5; total time=  26.7s\n",
      "[CV] END learning_rate=0.1, max_depth=6, n_estimators=100, objective=reg:squarederror, subsample=1; total time=   8.5s\n",
      "[CV] END learning_rate=0.3, max_depth=None, n_estimators=50, objective=reg:squaredlogerror, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.3, max_depth=None, n_estimators=50, objective=reg:squaredlogerror, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.3, max_depth=None, n_estimators=50, objective=reg:squaredlogerror, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.3, max_depth=None, n_estimators=50, objective=reg:squaredlogerror, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.3, max_depth=None, n_estimators=50, objective=reg:squaredlogerror, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.02, max_depth=6, n_estimators=500, objective=reg:squarederror, subsample=0.5; total time=  27.4s\n",
      "[CV] END learning_rate=0.1, max_depth=6, n_estimators=100, objective=reg:squarederror, subsample=1; total time=   8.4s\n",
      "[CV] END learning_rate=0.1, max_depth=6, n_estimators=100, objective=reg:squarederror, subsample=1; total time=   8.6s\n",
      "[CV] END learning_rate=0.3, max_depth=6, n_estimators=500, objective=reg:squarederror, subsample=0.5; total time=  12.0s\n",
      "[CV] END learning_rate=0.3, max_depth=6, n_estimators=500, objective=reg:squarederror, subsample=0.5; total time=  13.1s\n",
      "[CV] END learning_rate=0.3, max_depth=6, n_estimators=500, objective=reg:squarederror, subsample=0.5; total time=  10.7s\n",
      "[CV] END learning_rate=0.3, max_depth=6, n_estimators=500, objective=reg:squarederror, subsample=0.5; total time=  10.9s\n",
      "[CV] END learning_rate=0.3, max_depth=6, n_estimators=500, objective=reg:squarederror, subsample=0.5; total time=  11.4s\n",
      "[CV] END learning_rate=0.02, max_depth=10, n_estimators=500, objective=reg:squarederror, subsample=1; total time= 1.1min\n",
      "[CV] END learning_rate=0.02, max_depth=10, n_estimators=500, objective=reg:squarederror, subsample=1; total time= 1.1min\n",
      "[CV] END learning_rate=0.3, max_depth=6, n_estimators=200, objective=reg:squaredlogerror, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.3, max_depth=6, n_estimators=200, objective=reg:squaredlogerror, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.3, max_depth=6, n_estimators=200, objective=reg:squaredlogerror, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.3, max_depth=6, n_estimators=200, objective=reg:squaredlogerror, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.3, max_depth=6, n_estimators=200, objective=reg:squaredlogerror, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.02, max_depth=10, n_estimators=500, objective=reg:squarederror, subsample=1; total time= 1.1min\n",
      "[CV] END learning_rate=0.02, max_depth=10, n_estimators=500, objective=reg:squarederror, subsample=1; total time= 1.1min\n",
      "[CV] END learning_rate=0.02, max_depth=None, n_estimators=100, objective=reg:squarederror, subsample=0.5; total time=   8.5s\n",
      "[CV] END learning_rate=0.02, max_depth=None, n_estimators=100, objective=reg:squarederror, subsample=0.5; total time=   5.9s\n",
      "[CV] END learning_rate=0.02, max_depth=None, n_estimators=100, objective=reg:squarederror, subsample=0.5; total time=   5.6s\n",
      "[CV] END learning_rate=0.1, max_depth=6, n_estimators=100, objective=reg:squaredlogerror, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, max_depth=6, n_estimators=100, objective=reg:squaredlogerror, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, max_depth=6, n_estimators=100, objective=reg:squaredlogerror, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, max_depth=6, n_estimators=100, objective=reg:squaredlogerror, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, max_depth=6, n_estimators=100, objective=reg:squaredlogerror, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.02, max_depth=10, n_estimators=200, objective=reg:squaredlogerror, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.02, max_depth=10, n_estimators=200, objective=reg:squaredlogerror, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.02, max_depth=10, n_estimators=200, objective=reg:squaredlogerror, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.02, max_depth=10, n_estimators=200, objective=reg:squaredlogerror, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.02, max_depth=10, n_estimators=200, objective=reg:squaredlogerror, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.05, max_depth=None, n_estimators=200, objective=reg:squaredlogerror, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.05, max_depth=None, n_estimators=200, objective=reg:squaredlogerror, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.05, max_depth=None, n_estimators=200, objective=reg:squaredlogerror, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.05, max_depth=None, n_estimators=200, objective=reg:squaredlogerror, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.05, max_depth=None, n_estimators=200, objective=reg:squaredlogerror, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.02, max_depth=None, n_estimators=100, objective=reg:squarederror, subsample=0.5; total time=   8.8s\n",
      "[CV] END learning_rate=0.02, max_depth=None, n_estimators=100, objective=reg:squarederror, subsample=0.5; total time=   7.6s\n",
      "[CV] END learning_rate=0.02, max_depth=10, n_estimators=500, objective=reg:squarederror, subsample=1; total time=  43.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/claudio/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "75 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "19 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [18:51:42] /croot/xgboost-split_1675457761144/work/src/objective/regression_obj.cu:148: label must be greater than -1 for rmsle so that log(label + 1) can be valid.\n",
      "Stack trace:\n",
      "  [bt] (0) /home/claudio/anaconda3/lib/libxgboost.so(+0xc01d4) [0x7fa0c38c01d4]\n",
      "  [bt] (1) /home/claudio/anaconda3/lib/libxgboost.so(+0x3b755c) [0x7fa0c3bb755c]\n",
      "  [bt] (2) /home/claudio/anaconda3/lib/libxgboost.so(+0x29f9be) [0x7fa0c3a9f9be]\n",
      "  [bt] (3) /home/claudio/anaconda3/lib/libxgboost.so(XGBoosterUpdateOneIter+0x6c) [0x7fa0c38cbfbc]\n",
      "  [bt] (4) /home/claudio/anaconda3/lib/python3.9/lib-dynload/../../libffi.so.8(+0xa052) [0x7fa0da5c4052]\n",
      "  [bt] (5) /home/claudio/anaconda3/lib/python3.9/lib-dynload/../../libffi.so.8(+0x8925) [0x7fa0da5c2925]\n",
      "  [bt] (6) /home/claudio/anaconda3/lib/python3.9/lib-dynload/../../libffi.so.8(ffi_call+0xde) [0x7fa0da5c306e]\n",
      "  [bt] (7) /home/claudio/anaconda3/lib/python3.9/lib-dynload/_ctypes.cpython-39-x86_64-linux-gnu.so(+0x91e0) [0x7fa0d94ff1e0]\n",
      "  [bt] (8) /home/claudio/anaconda3/lib/python3.9/lib-dynload/_ctypes.cpython-39-x86_64-linux-gnu.so(+0x8568) [0x7fa0d94fe568]\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [18:51:42] /croot/xgboost-split_1675457761144/work/src/objective/regression_obj.cu:148: label must be greater than -1 for rmsle so that log(label + 1) can be valid.\n",
      "Stack trace:\n",
      "  [bt] (0) /home/claudio/anaconda3/lib/libxgboost.so(+0xc01d4) [0x7f46574c01d4]\n",
      "  [bt] (1) /home/claudio/anaconda3/lib/libxgboost.so(+0x3b755c) [0x7f46577b755c]\n",
      "  [bt] (2) /home/claudio/anaconda3/lib/libxgboost.so(+0x29f9be) [0x7f465769f9be]\n",
      "  [bt] (3) /home/claudio/anaconda3/lib/libxgboost.so(XGBoosterUpdateOneIter+0x6c) [0x7f46574cbfbc]\n",
      "  [bt] (4) /home/claudio/anaconda3/lib/python3.9/lib-dynload/../../libffi.so.8(+0xa052) [0x7f466e2e5052]\n",
      "  [bt] (5) /home/claudio/anaconda3/lib/python3.9/lib-dynload/../../libffi.so.8(+0x8925) [0x7f466e2e3925]\n",
      "  [bt] (6) /home/claudio/anaconda3/lib/python3.9/lib-dynload/../../libffi.so.8(ffi_call+0xde) [0x7f466e2e406e]\n",
      "  [bt] (7) /home/claudio/anaconda3/lib/python3.9/lib-dynload/_ctypes.cpython-39-x86_64-linux-gnu.so(+0x91e0) [0x7f466d1e51e0]\n",
      "  [bt] (8) /home/claudio/anaconda3/lib/python3.9/lib-dynload/_ctypes.cpython-39-x86_64-linux-gnu.so(+0x8568) [0x7f466d1e4568]\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [18:51:53] /croot/xgboost-split_1675457761144/work/src/objective/regression_obj.cu:148: label must be greater than -1 for rmsle so that log(label + 1) can be valid.\n",
      "Stack trace:\n",
      "  [bt] (0) /home/claudio/anaconda3/lib/libxgboost.so(+0xc01d4) [0x7f46574c01d4]\n",
      "  [bt] (1) /home/claudio/anaconda3/lib/libxgboost.so(+0x3b755c) [0x7f46577b755c]\n",
      "  [bt] (2) /home/claudio/anaconda3/lib/libxgboost.so(+0x29f9be) [0x7f465769f9be]\n",
      "  [bt] (3) /home/claudio/anaconda3/lib/libxgboost.so(XGBoosterUpdateOneIter+0x6c) [0x7f46574cbfbc]\n",
      "  [bt] (4) /home/claudio/anaconda3/lib/python3.9/lib-dynload/../../libffi.so.8(+0xa052) [0x7f466e2e5052]\n",
      "  [bt] (5) /home/claudio/anaconda3/lib/python3.9/lib-dynload/../../libffi.so.8(+0x8925) [0x7f466e2e3925]\n",
      "  [bt] (6) /home/claudio/anaconda3/lib/python3.9/lib-dynload/../../libffi.so.8(ffi_call+0xde) [0x7f466e2e406e]\n",
      "  [bt] (7) /home/claudio/anaconda3/lib/python3.9/lib-dynload/_ctypes.cpython-39-x86_64-linux-gnu.so(+0x91e0) [0x7f466d1e51e0]\n",
      "  [bt] (8) /home/claudio/anaconda3/lib/python3.9/lib-dynload/_ctypes.cpython-39-x86_64-linux-gnu.so(+0x8568) [0x7f466d1e4568]\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [18:51:50] /croot/xgboost-split_1675457761144/work/src/objective/regression_obj.cu:148: label must be greater than -1 for rmsle so that log(label + 1) can be valid.\n",
      "Stack trace:\n",
      "  [bt] (0) /home/claudio/anaconda3/lib/libxgboost.so(+0xc01d4) [0x7fa0c38c01d4]\n",
      "  [bt] (1) /home/claudio/anaconda3/lib/libxgboost.so(+0x3b755c) [0x7fa0c3bb755c]\n",
      "  [bt] (2) /home/claudio/anaconda3/lib/libxgboost.so(+0x29f9be) [0x7fa0c3a9f9be]\n",
      "  [bt] (3) /home/claudio/anaconda3/lib/libxgboost.so(XGBoosterUpdateOneIter+0x6c) [0x7fa0c38cbfbc]\n",
      "  [bt] (4) /home/claudio/anaconda3/lib/python3.9/lib-dynload/../../libffi.so.8(+0xa052) [0x7fa0da5c4052]\n",
      "  [bt] (5) /home/claudio/anaconda3/lib/python3.9/lib-dynload/../../libffi.so.8(+0x8925) [0x7fa0da5c2925]\n",
      "  [bt] (6) /home/claudio/anaconda3/lib/python3.9/lib-dynload/../../libffi.so.8(ffi_call+0xde) [0x7fa0da5c306e]\n",
      "  [bt] (7) /home/claudio/anaconda3/lib/python3.9/lib-dynload/_ctypes.cpython-39-x86_64-linux-gnu.so(+0x91e0) [0x7fa0d94ff1e0]\n",
      "  [bt] (8) /home/claudio/anaconda3/lib/python3.9/lib-dynload/_ctypes.cpython-39-x86_64-linux-gnu.so(+0x8568) [0x7fa0d94fe568]\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [18:51:57] /croot/xgboost-split_1675457761144/work/src/objective/regression_obj.cu:148: label must be greater than -1 for rmsle so that log(label + 1) can be valid.\n",
      "Stack trace:\n",
      "  [bt] (0) /home/claudio/anaconda3/lib/libxgboost.so(+0xc01d4) [0x7f92f0cc01d4]\n",
      "  [bt] (1) /home/claudio/anaconda3/lib/libxgboost.so(+0x3b755c) [0x7f92f0fb755c]\n",
      "  [bt] (2) /home/claudio/anaconda3/lib/libxgboost.so(+0x29f9be) [0x7f92f0e9f9be]\n",
      "  [bt] (3) /home/claudio/anaconda3/lib/libxgboost.so(XGBoosterUpdateOneIter+0x6c) [0x7f92f0ccbfbc]\n",
      "  [bt] (4) /home/claudio/anaconda3/lib/python3.9/lib-dynload/../../libffi.so.8(+0xa052) [0x7f9307a0a052]\n",
      "  [bt] (5) /home/claudio/anaconda3/lib/python3.9/lib-dynload/../../libffi.so.8(+0x8925) [0x7f9307a08925]\n",
      "  [bt] (6) /home/claudio/anaconda3/lib/python3.9/lib-dynload/../../libffi.so.8(ffi_call+0xde) [0x7f9307a0906e]\n",
      "  [bt] (7) /home/claudio/anaconda3/lib/python3.9/lib-dynload/_ctypes.cpython-39-x86_64-linux-gnu.so(+0x91e0) [0x7f930692a1e0]\n",
      "  [bt] (8) /home/claudio/anaconda3/lib/python3.9/lib-dynload/_ctypes.cpython-39-x86_64-linux-gnu.so(+0x8568) [0x7f9306929568]\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [18:51:54] /croot/xgboost-split_1675457761144/work/src/objective/regression_obj.cu:148: label must be greater than -1 for rmsle so that log(label + 1) can be valid.\n",
      "Stack trace:\n",
      "  [bt] (0) /home/claudio/anaconda3/lib/libxgboost.so(+0xc01d4) [0x7f70af0c01d4]\n",
      "  [bt] (1) /home/claudio/anaconda3/lib/libxgboost.so(+0x3b755c) [0x7f70af3b755c]\n",
      "  [bt] (2) /home/claudio/anaconda3/lib/libxgboost.so(+0x29f9be) [0x7f70af29f9be]\n",
      "  [bt] (3) /home/claudio/anaconda3/lib/libxgboost.so(XGBoosterUpdateOneIter+0x6c) [0x7f70af0cbfbc]\n",
      "  [bt] (4) /home/claudio/anaconda3/lib/python3.9/lib-dynload/../../libffi.so.8(+0xa052) [0x7f70c5ee5052]\n",
      "  [bt] (5) /home/claudio/anaconda3/lib/python3.9/lib-dynload/../../libffi.so.8(+0x8925) [0x7f70c5ee3925]\n",
      "  [bt] (6) /home/claudio/anaconda3/lib/python3.9/lib-dynload/../../libffi.so.8(ffi_call+0xde) [0x7f70c5ee406e]\n",
      "  [bt] (7) /home/claudio/anaconda3/lib/python3.9/lib-dynload/_ctypes.cpython-39-x86_64-linux-gnu.so(+0x91e0) [0x7f70c4de51e0]\n",
      "  [bt] (8) /home/claudio/anaconda3/lib/python3.9/lib-dynload/_ctypes.cpython-39-x86_64-linux-gnu.so(+0x8568) [0x7f70c4de4568]\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [18:52:15] /croot/xgboost-split_1675457761144/work/src/objective/regression_obj.cu:148: label must be greater than -1 for rmsle so that log(label + 1) can be valid.\n",
      "Stack trace:\n",
      "  [bt] (0) /home/claudio/anaconda3/lib/libxgboost.so(+0xc01d4) [0x7f92f0cc01d4]\n",
      "  [bt] (1) /home/claudio/anaconda3/lib/libxgboost.so(+0x3b755c) [0x7f92f0fb755c]\n",
      "  [bt] (2) /home/claudio/anaconda3/lib/libxgboost.so(+0x29f9be) [0x7f92f0e9f9be]\n",
      "  [bt] (3) /home/claudio/anaconda3/lib/libxgboost.so(XGBoosterUpdateOneIter+0x6c) [0x7f92f0ccbfbc]\n",
      "  [bt] (4) /home/claudio/anaconda3/lib/python3.9/lib-dynload/../../libffi.so.8(+0xa052) [0x7f9307a0a052]\n",
      "  [bt] (5) /home/claudio/anaconda3/lib/python3.9/lib-dynload/../../libffi.so.8(+0x8925) [0x7f9307a08925]\n",
      "  [bt] (6) /home/claudio/anaconda3/lib/python3.9/lib-dynload/../../libffi.so.8(ffi_call+0xde) [0x7f9307a0906e]\n",
      "  [bt] (7) /home/claudio/anaconda3/lib/python3.9/lib-dynload/_ctypes.cpython-39-x86_64-linux-gnu.so(+0x91e0) [0x7f930692a1e0]\n",
      "  [bt] (8) /home/claudio/anaconda3/lib/python3.9/lib-dynload/_ctypes.cpython-39-x86_64-linux-gnu.so(+0x8568) [0x7f9306929568]\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [18:52:28] /croot/xgboost-split_1675457761144/work/src/objective/regression_obj.cu:148: label must be greater than -1 for rmsle so that log(label + 1) can be valid.\n",
      "Stack trace:\n",
      "  [bt] (0) /home/claudio/anaconda3/lib/libxgboost.so(+0xc01d4) [0x7f46574c01d4]\n",
      "  [bt] (1) /home/claudio/anaconda3/lib/libxgboost.so(+0x3b755c) [0x7f46577b755c]\n",
      "  [bt] (2) /home/claudio/anaconda3/lib/libxgboost.so(+0x29f9be) [0x7f465769f9be]\n",
      "  [bt] (3) /home/claudio/anaconda3/lib/libxgboost.so(XGBoosterUpdateOneIter+0x6c) [0x7f46574cbfbc]\n",
      "  [bt] (4) /home/claudio/anaconda3/lib/python3.9/lib-dynload/../../libffi.so.8(+0xa052) [0x7f466e2e5052]\n",
      "  [bt] (5) /home/claudio/anaconda3/lib/python3.9/lib-dynload/../../libffi.so.8(+0x8925) [0x7f466e2e3925]\n",
      "  [bt] (6) /home/claudio/anaconda3/lib/python3.9/lib-dynload/../../libffi.so.8(ffi_call+0xde) [0x7f466e2e406e]\n",
      "  [bt] (7) /home/claudio/anaconda3/lib/python3.9/lib-dynload/_ctypes.cpython-39-x86_64-linux-gnu.so(+0x91e0) [0x7f466d1e51e0]\n",
      "  [bt] (8) /home/claudio/anaconda3/lib/python3.9/lib-dynload/_ctypes.cpython-39-x86_64-linux-gnu.so(+0x8568) [0x7f466d1e4568]\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [18:52:47] /croot/xgboost-split_1675457761144/work/src/objective/regression_obj.cu:148: label must be greater than -1 for rmsle so that log(label + 1) can be valid.\n",
      "Stack trace:\n",
      "  [bt] (0) /home/claudio/anaconda3/lib/libxgboost.so(+0xc01d4) [0x7f46574c01d4]\n",
      "  [bt] (1) /home/claudio/anaconda3/lib/libxgboost.so(+0x3b755c) [0x7f46577b755c]\n",
      "  [bt] (2) /home/claudio/anaconda3/lib/libxgboost.so(+0x29f9be) [0x7f465769f9be]\n",
      "  [bt] (3) /home/claudio/anaconda3/lib/libxgboost.so(XGBoosterUpdateOneIter+0x6c) [0x7f46574cbfbc]\n",
      "  [bt] (4) /home/claudio/anaconda3/lib/python3.9/lib-dynload/../../libffi.so.8(+0xa052) [0x7f466e2e5052]\n",
      "  [bt] (5) /home/claudio/anaconda3/lib/python3.9/lib-dynload/../../libffi.so.8(+0x8925) [0x7f466e2e3925]\n",
      "  [bt] (6) /home/claudio/anaconda3/lib/python3.9/lib-dynload/../../libffi.so.8(ffi_call+0xde) [0x7f466e2e406e]\n",
      "  [bt] (7) /home/claudio/anaconda3/lib/python3.9/lib-dynload/_ctypes.cpython-39-x86_64-linux-gnu.so(+0x91e0) [0x7f466d1e51e0]\n",
      "  [bt] (8) /home/claudio/anaconda3/lib/python3.9/lib-dynload/_ctypes.cpython-39-x86_64-linux-gnu.so(+0x8568) [0x7f466d1e4568]\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [18:54:39] /croot/xgboost-split_1675457761144/work/src/objective/regression_obj.cu:148: label must be greater than -1 for rmsle so that log(label + 1) can be valid.\n",
      "Stack trace:\n",
      "  [bt] (0) /home/claudio/anaconda3/lib/libxgboost.so(+0xc01d4) [0x7fa0c38c01d4]\n",
      "  [bt] (1) /home/claudio/anaconda3/lib/libxgboost.so(+0x3b755c) [0x7fa0c3bb755c]\n",
      "  [bt] (2) /home/claudio/anaconda3/lib/libxgboost.so(+0x29f9be) [0x7fa0c3a9f9be]\n",
      "  [bt] (3) /home/claudio/anaconda3/lib/libxgboost.so(XGBoosterUpdateOneIter+0x6c) [0x7fa0c38cbfbc]\n",
      "  [bt] (4) /home/claudio/anaconda3/lib/python3.9/lib-dynload/../../libffi.so.8(+0xa052) [0x7fa0da5c4052]\n",
      "  [bt] (5) /home/claudio/anaconda3/lib/python3.9/lib-dynload/../../libffi.so.8(+0x8925) [0x7fa0da5c2925]\n",
      "  [bt] (6) /home/claudio/anaconda3/lib/python3.9/lib-dynload/../../libffi.so.8(ffi_call+0xde) [0x7fa0da5c306e]\n",
      "  [bt] (7) /home/claudio/anaconda3/lib/python3.9/lib-dynload/_ctypes.cpython-39-x86_64-linux-gnu.so(+0x91e0) [0x7fa0d94ff1e0]\n",
      "  [bt] (8) /home/claudio/anaconda3/lib/python3.9/lib-dynload/_ctypes.cpython-39-x86_64-linux-gnu.so(+0x8568) [0x7fa0d94fe568]\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [18:56:01] /croot/xgboost-split_1675457761144/work/src/objective/regression_obj.cu:148: label must be greater than -1 for rmsle so that log(label + 1) can be valid.\n",
      "Stack trace:\n",
      "  [bt] (0) /home/claudio/anaconda3/lib/libxgboost.so(+0xc01d4) [0x7f70af0c01d4]\n",
      "  [bt] (1) /home/claudio/anaconda3/lib/libxgboost.so(+0x3b755c) [0x7f70af3b755c]\n",
      "  [bt] (2) /home/claudio/anaconda3/lib/libxgboost.so(+0x29f9be) [0x7f70af29f9be]\n",
      "  [bt] (3) /home/claudio/anaconda3/lib/libxgboost.so(XGBoosterUpdateOneIter+0x6c) [0x7f70af0cbfbc]\n",
      "  [bt] (4) /home/claudio/anaconda3/lib/python3.9/lib-dynload/../../libffi.so.8(+0xa052) [0x7f70c5ee5052]\n",
      "  [bt] (5) /home/claudio/anaconda3/lib/python3.9/lib-dynload/../../libffi.so.8(+0x8925) [0x7f70c5ee3925]\n",
      "  [bt] (6) /home/claudio/anaconda3/lib/python3.9/lib-dynload/../../libffi.so.8(ffi_call+0xde) [0x7f70c5ee406e]\n",
      "  [bt] (7) /home/claudio/anaconda3/lib/python3.9/lib-dynload/_ctypes.cpython-39-x86_64-linux-gnu.so(+0x91e0) [0x7f70c4de51e0]\n",
      "  [bt] (8) /home/claudio/anaconda3/lib/python3.9/lib-dynload/_ctypes.cpython-39-x86_64-linux-gnu.so(+0x8568) [0x7f70c4de4568]\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/home/claudio/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [18:56:16] /croot/xgboost-split_1675457761144/work/src/objective/regression_obj.cu:148: label must be greater than -1 for rmsle so that log(label + 1) can be valid.\n",
      "Stack trace:\n",
      "  [bt] (0) /home/claudio/anaconda3/lib/libxgboost.so(+0xc01d4) [0x7f46574c01d4]\n",
      "  [bt] (1) /home/claudio/anaconda3/lib/libxgboost.so(+0x3b755c) [0x7f46577b755c]\n",
      "  [bt] (2) /home/claudio/anaconda3/lib/libxgboost.so(+0x29f9be) [0x7f465769f9be]\n",
      "  [bt] (3) /home/claudio/anaconda3/lib/libxgboost.so(XGBoosterUpdateOneIter+0x6c) [0x7f46574cbfbc]\n",
      "  [bt] (4) /home/claudio/anaconda3/lib/python3.9/lib-dynload/../../libffi.so.8(+0xa052) [0x7f466e2e5052]\n",
      "  [bt] (5) /home/claudio/anaconda3/lib/python3.9/lib-dynload/../../libffi.so.8(+0x8925) [0x7f466e2e3925]\n",
      "  [bt] (6) /home/claudio/anaconda3/lib/python3.9/lib-dynload/../../libffi.so.8(ffi_call+0xde) [0x7f466e2e406e]\n",
      "  [bt] (7) /home/claudio/anaconda3/lib/python3.9/lib-dynload/_ctypes.cpython-39-x86_64-linux-gnu.so(+0x91e0) [0x7f466d1e51e0]\n",
      "  [bt] (8) /home/claudio/anaconda3/lib/python3.9/lib-dynload/_ctypes.cpython-39-x86_64-linux-gnu.so(+0x8568) [0x7f466d1e4568]\n",
      "\n",
      "\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/claudio/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.09439591        nan        nan        nan        nan 0.75915893\n",
      " 0.80587799        nan 0.74806705        nan 0.83568065        nan\n",
      "        nan 0.81429157        nan 0.80980564 0.66696078        nan\n",
      " 0.82523854 0.79883688 0.83568065 0.80980564        nan 0.74801534\n",
      " 0.79854007        nan 0.66700399        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "/home/claudio/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the train scores are non-finite: [0.22912404        nan        nan        nan        nan 0.99999983\n",
      " 0.99631816        nan 0.99999797        nan 0.99869249        nan\n",
      "        nan 0.98404349        nan 0.99992669 0.86937003        nan\n",
      " 0.99999811 0.9999986  0.99869249 0.99992669        nan 0.99999984\n",
      " 0.99999841        nan 0.8264546         nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params, best score: 0.8357 {'subsample': 0.5, 'objective': 'reg:squarederror', 'n_estimators': 500, 'max_depth': None, 'learning_rate': 0.02}\n"
     ]
    }
   ],
   "source": [
    "parameters = {'max_depth':[6,10,None], 'n_estimators':[50, 100, 200,500], \n",
    "              'learning_rate': [0.02,0.05,0.1,0.3], 'objective':['reg:squarederror',\n",
    "                'reg:squaredlogerror'], 'subsample':[0.5,1]}\n",
    "\n",
    "nmodels = np.product([len(el) for el in parameters.values()])\n",
    "model = RandomizedSearchCV(xgb.XGBRegressor(), parameters, cv = KFold(n_splits=5, shuffle=True), \\\n",
    "                     verbose = 2, n_jobs = 4, return_train_score=True, n_iter = 30)\n",
    "model.fit(reduced_spectra,log_tau.values.ravel())\n",
    "\n",
    "print('Best params, best score:', \"{:.4f}\".format(model.best_score_), \\\n",
    "      model.best_params_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My first attempt was running xgb, just because it worked well for me with dust and I wanted to see if the trend would continue. The score itself is not poor at a test score of 0.83, but due to the errors that occured when validating the mode (likely to the negative values of log_tau), I did not want to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=6, n_estimators=20; total time=   1.8s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=6, n_estimators=20; total time=   1.8s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=6, n_estimators=20; total time=   1.9s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=6, n_estimators=20; total time=   1.8s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=6, n_estimators=20; total time=   1.9s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=6, n_estimators=50; total time=   4.9s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=6, n_estimators=50; total time=   4.8s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=6, n_estimators=50; total time=   4.8s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=6, n_estimators=50; total time=   5.0s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=6, n_estimators=50; total time=   6.3s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=6, n_estimators=100; total time=  13.5s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=6, n_estimators=100; total time=  13.5s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=6, n_estimators=100; total time=  14.1s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=10, n_estimators=20; total time=   3.8s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=10, n_estimators=20; total time=   3.9s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=6, n_estimators=100; total time=  14.4s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=10, n_estimators=20; total time=   3.8s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=10, n_estimators=20; total time=   3.8s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=10, n_estimators=20; total time=   3.8s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=6, n_estimators=100; total time=  13.9s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=10, n_estimators=50; total time=   9.4s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=10, n_estimators=50; total time=   9.4s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=10, n_estimators=50; total time=   9.6s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=10, n_estimators=50; total time=   9.4s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=10, n_estimators=50; total time=   9.2s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=10, n_estimators=100; total time=  18.6s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=10, n_estimators=100; total time=  19.1s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=10, n_estimators=100; total time=  18.7s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=None, n_estimators=20; total time=   4.6s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=10, n_estimators=100; total time=  18.6s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=None, n_estimators=20; total time=   5.3s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=None, n_estimators=20; total time=   5.6s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=None, n_estimators=20; total time=   5.6s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=None, n_estimators=20; total time=   6.0s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=10, n_estimators=100; total time=  21.5s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=None, n_estimators=50; total time=  14.2s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=None, n_estimators=50; total time=  14.6s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=None, n_estimators=50; total time=  14.7s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=None, n_estimators=50; total time=  13.7s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=None, n_estimators=50; total time=  14.4s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=None, n_estimators=100; total time=  28.6s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=None, n_estimators=100; total time=  30.9s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=6, n_estimators=20; total time=   3.5s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=None, n_estimators=100; total time=  29.9s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=6, n_estimators=20; total time=   3.5s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=6, n_estimators=20; total time=   3.5s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=None, n_estimators=100; total time=  28.9s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=6, n_estimators=20; total time=   3.7s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=6, n_estimators=20; total time=   3.7s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=6, n_estimators=50; total time=   9.6s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=6, n_estimators=50; total time=   9.1s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=6, n_estimators=50; total time=   9.0s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=None, n_estimators=100; total time=  30.0s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=6, n_estimators=50; total time=   8.7s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=6, n_estimators=50; total time=   8.7s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=6, n_estimators=100; total time=  17.4s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=6, n_estimators=100; total time=  16.3s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=6, n_estimators=100; total time=  16.3s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=6, n_estimators=100; total time=  16.2s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=10, n_estimators=20; total time=   4.6s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=10, n_estimators=20; total time=   4.1s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=10, n_estimators=20; total time=   4.0s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=10, n_estimators=20; total time=   4.1s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=10, n_estimators=20; total time=   4.6s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=6, n_estimators=100; total time=  16.9s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=10, n_estimators=50; total time=  12.1s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=10, n_estimators=50; total time=  12.2s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=10, n_estimators=50; total time=  12.1s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=10, n_estimators=50; total time=  12.0s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=10, n_estimators=50; total time=  11.7s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=10, n_estimators=100; total time=  24.1s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=10, n_estimators=100; total time=  24.3s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=10, n_estimators=100; total time=  24.8s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=None, n_estimators=20; total time=   4.5s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=None, n_estimators=20; total time=   4.0s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=None, n_estimators=20; total time=   3.7s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=10, n_estimators=100; total time=  23.9s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=None, n_estimators=20; total time=   4.1s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=None, n_estimators=20; total time=   4.0s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=None, n_estimators=50; total time=  11.5s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=10, n_estimators=100; total time=  23.2s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=None, n_estimators=50; total time=  11.9s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=None, n_estimators=50; total time=  12.0s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=None, n_estimators=50; total time=  13.3s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=None, n_estimators=50; total time=  13.3s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=None, n_estimators=100; total time=  28.5s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=None, n_estimators=100; total time=  28.3s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=6, n_estimators=20; total time=   3.3s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=6, n_estimators=20; total time=   3.3s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=None, n_estimators=100; total time=  28.6s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=6, n_estimators=20; total time=   3.3s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=None, n_estimators=100; total time=  28.4s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=6, n_estimators=20; total time=   3.4s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=6, n_estimators=20; total time=   3.4s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=6, n_estimators=50; total time=   8.3s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=6, n_estimators=50; total time=   7.7s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=6, n_estimators=50; total time=   7.6s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=None, n_estimators=100; total time=  26.6s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=6, n_estimators=50; total time=   7.4s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=6, n_estimators=50; total time=   7.3s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=6, n_estimators=100; total time=  15.6s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=6, n_estimators=100; total time=  16.3s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=6, n_estimators=100; total time=  16.5s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=6, n_estimators=100; total time=  16.7s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=10, n_estimators=20; total time=   4.6s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=10, n_estimators=20; total time=   4.7s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=10, n_estimators=20; total time=   4.6s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=10, n_estimators=20; total time=   4.6s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=10, n_estimators=20; total time=   4.7s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=6, n_estimators=100; total time=  17.3s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=10, n_estimators=50; total time=  12.1s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=10, n_estimators=50; total time=  12.7s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=10, n_estimators=50; total time=  12.5s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=10, n_estimators=50; total time=  12.4s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=10, n_estimators=50; total time=  12.3s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=10, n_estimators=100; total time=  25.5s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=10, n_estimators=100; total time=  26.8s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=10, n_estimators=100; total time=  25.9s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=None, n_estimators=20; total time=   5.0s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=None, n_estimators=20; total time=   4.9s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=10, n_estimators=100; total time=  24.9s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=None, n_estimators=20; total time=   4.5s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=None, n_estimators=20; total time=   4.2s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=None, n_estimators=20; total time=   4.4s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=10, n_estimators=100; total time=  22.8s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=None, n_estimators=50; total time=  12.0s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=None, n_estimators=50; total time=  12.3s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=None, n_estimators=50; total time=  12.6s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=None, n_estimators=50; total time=  12.6s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=None, n_estimators=50; total time=  13.4s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=None, n_estimators=100; total time=  13.1s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=None, n_estimators=100; total time=  13.7s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=6, n_estimators=20; total time=   3.5s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=6, n_estimators=20; total time=   3.5s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=None, n_estimators=100; total time=  13.7s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=6, n_estimators=20; total time=   3.4s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=None, n_estimators=100; total time=  13.2s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=None, n_estimators=100; total time=  13.5s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=6, n_estimators=20; total time=   3.4s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=6, n_estimators=20; total time=   3.5s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=6, n_estimators=50; total time=   9.0s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=6, n_estimators=50; total time=   8.8s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=6, n_estimators=50; total time=   8.7s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=6, n_estimators=50; total time=   8.8s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=6, n_estimators=50; total time=   8.7s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=6, n_estimators=100; total time=  17.7s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=6, n_estimators=100; total time=  17.7s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=6, n_estimators=100; total time=  17.7s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=10, n_estimators=20; total time=   4.9s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=10, n_estimators=20; total time=   4.9s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=6, n_estimators=100; total time=  17.7s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=10, n_estimators=20; total time=   4.2s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=10, n_estimators=20; total time=   4.2s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=10, n_estimators=20; total time=   4.2s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=6, n_estimators=100; total time=  17.5s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=10, n_estimators=50; total time=  12.6s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=10, n_estimators=50; total time=  12.2s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=10, n_estimators=50; total time=  12.2s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=10, n_estimators=50; total time=  12.1s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=10, n_estimators=50; total time=  11.9s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=10, n_estimators=100; total time=  25.7s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=10, n_estimators=100; total time=  25.4s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=None, n_estimators=20; total time=   5.7s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=10, n_estimators=100; total time=  26.5s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=None, n_estimators=20; total time=   5.4s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=None, n_estimators=20; total time=   5.6s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=10, n_estimators=100; total time=  26.5s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=None, n_estimators=20; total time=   5.8s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=None, n_estimators=20; total time=   5.4s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=10, n_estimators=100; total time=  26.6s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=None, n_estimators=50; total time=  16.3s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=None, n_estimators=50; total time=  15.7s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=None, n_estimators=50; total time=  16.3s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=None, n_estimators=50; total time=  15.2s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=None, n_estimators=50; total time=  15.9s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=None, n_estimators=100; total time=  31.2s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=None, n_estimators=100; total time=  30.9s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=6, n_estimators=20; total time=   3.4s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=6, n_estimators=20; total time=   3.5s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=None, n_estimators=100; total time=  30.6s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=6, n_estimators=20; total time=   3.4s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=6, n_estimators=20; total time=   3.4s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=None, n_estimators=100; total time=  31.7s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=6, n_estimators=20; total time=   3.5s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=6, n_estimators=50; total time=   8.6s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=6, n_estimators=50; total time=   8.6s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=6, n_estimators=50; total time=   8.7s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=6, n_estimators=50; total time=   8.7s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=6, n_estimators=50; total time=   8.8s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=None, n_estimators=100; total time=  34.3s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=6, n_estimators=100; total time=  17.5s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=6, n_estimators=100; total time=  17.3s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=6, n_estimators=100; total time=  17.3s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=10, n_estimators=20; total time=   4.9s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=6, n_estimators=100; total time=  17.4s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=10, n_estimators=20; total time=   5.0s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=10, n_estimators=20; total time=   4.9s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=10, n_estimators=20; total time=   5.0s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=10, n_estimators=20; total time=   4.8s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=6, n_estimators=100; total time=  17.8s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=10, n_estimators=50; total time=  13.3s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=10, n_estimators=50; total time=  13.4s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=10, n_estimators=50; total time=  13.4s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=10, n_estimators=50; total time=  13.3s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=10, n_estimators=50; total time=  13.2s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=10, n_estimators=100; total time=  18.3s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=10, n_estimators=100; total time=  18.5s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=10, n_estimators=100; total time=  20.5s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=None, n_estimators=20; total time=   4.4s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=None, n_estimators=20; total time=   4.6s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=10, n_estimators=100; total time=  15.7s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=None, n_estimators=20; total time=   5.1s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=None, n_estimators=20; total time=   5.2s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=None, n_estimators=20; total time=   5.8s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=10, n_estimators=100; total time=  16.6s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=None, n_estimators=50; total time=   6.9s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=None, n_estimators=50; total time=   7.2s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=None, n_estimators=50; total time=   7.1s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=None, n_estimators=50; total time=   6.9s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=None, n_estimators=50; total time=   7.0s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=None, n_estimators=100; total time=   6.9s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=None, n_estimators=100; total time=   7.2s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=None, n_estimators=100; total time=   7.3s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=None, n_estimators=100; total time=   6.8s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=None, n_estimators=100; total time=   7.0s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=6, n_estimators=20; total time=   3.6s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=6, n_estimators=20; total time=   3.6s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=6, n_estimators=20; total time=   3.4s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=6, n_estimators=20; total time=   3.5s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=6, n_estimators=20; total time=   3.5s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=6, n_estimators=50; total time=   9.1s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=6, n_estimators=50; total time=   9.0s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=6, n_estimators=50; total time=   8.9s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=6, n_estimators=50; total time=   8.9s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=6, n_estimators=50; total time=   9.2s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=6, n_estimators=100; total time=  18.0s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=6, n_estimators=100; total time=  18.0s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=6, n_estimators=100; total time=  17.9s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=10, n_estimators=20; total time=   5.0s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=10, n_estimators=20; total time=   5.0s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=6, n_estimators=100; total time=  18.3s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=10, n_estimators=20; total time=   5.1s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=10, n_estimators=20; total time=   5.1s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=10, n_estimators=20; total time=   5.2s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=6, n_estimators=100; total time=  17.9s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=10, n_estimators=50; total time=  13.1s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=10, n_estimators=50; total time=  13.1s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=10, n_estimators=50; total time=  13.5s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=10, n_estimators=50; total time=  13.2s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=10, n_estimators=50; total time=  13.4s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=10, n_estimators=100; total time=  24.6s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=10, n_estimators=100; total time=  23.7s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=10, n_estimators=100; total time=  23.5s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=None, n_estimators=20; total time=   6.6s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=None, n_estimators=20; total time=   6.5s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=10, n_estimators=100; total time=  24.3s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=None, n_estimators=20; total time=   5.9s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=None, n_estimators=20; total time=   6.7s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=None, n_estimators=20; total time=   6.7s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=10, n_estimators=100; total time=  26.5s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=None, n_estimators=50; total time=  17.5s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=None, n_estimators=50; total time=  17.5s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=None, n_estimators=50; total time=  17.4s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=None, n_estimators=50; total time=  18.0s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=None, n_estimators=50; total time=  17.5s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=None, n_estimators=100; total time=  35.8s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=None, n_estimators=100; total time=  36.9s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=None, n_estimators=100; total time=  34.4s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=None, n_estimators=100; total time=  34.0s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=None, n_estimators=100; total time=  25.7s\n",
      "Best params, best score: 0.8262 {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 6, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "parameters = {'max_depth':[6,10,None], 'loss':['squared_error','absolute_error'], \n",
    "              'n_estimators':[20,50,100], 'learning_rate': [0.1,0.3,0.5]}\n",
    "nmodels = np.product([len(el) for el in parameters.values()])\n",
    "model = GridSearchCV(GradientBoostingRegressor(), parameters, \n",
    "                     cv = KFold(n_splits=5, shuffle=True, random_state = 5), \\\n",
    "                     verbose = 2, n_jobs = 4, return_train_score=True)\n",
    "model.fit(reduced_spectra,log_tau.values.ravel())\n",
    "\n",
    "print('Best params, best score:', \"{:.4f}\".format(model.best_score_), \\\n",
    "      model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'squared_error'...</td>\n",
       "      <td>0.826202</td>\n",
       "      <td>0.014619</td>\n",
       "      <td>0.999207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'absolute_error...</td>\n",
       "      <td>0.821656</td>\n",
       "      <td>0.027335</td>\n",
       "      <td>0.980243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'squared_error'...</td>\n",
       "      <td>0.819588</td>\n",
       "      <td>0.015056</td>\n",
       "      <td>0.996596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>{'learning_rate': 0.3, 'loss': 'squared_error'...</td>\n",
       "      <td>0.811238</td>\n",
       "      <td>0.021421</td>\n",
       "      <td>0.999991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>{'learning_rate': 0.3, 'loss': 'squared_error'...</td>\n",
       "      <td>0.810016</td>\n",
       "      <td>0.018133</td>\n",
       "      <td>0.999697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               params  mean_test_score  \\\n",
       "2   {'learning_rate': 0.1, 'loss': 'squared_error'...         0.826202   \n",
       "17  {'learning_rate': 0.1, 'loss': 'absolute_error...         0.821656   \n",
       "1   {'learning_rate': 0.1, 'loss': 'squared_error'...         0.819588   \n",
       "20  {'learning_rate': 0.3, 'loss': 'squared_error'...         0.811238   \n",
       "19  {'learning_rate': 0.3, 'loss': 'squared_error'...         0.810016   \n",
       "\n",
       "    std_test_score  mean_train_score  \n",
       "2         0.014619          0.999207  \n",
       "17        0.027335          0.980243  \n",
       "1         0.015056          0.996596  \n",
       "20        0.021421          0.999991  \n",
       "19        0.018133          0.999697  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#GBR scores\n",
    "\n",
    "scores = pd.DataFrame(model.cv_results_)\n",
    "scoresCV = scores[['params','mean_test_score','std_test_score','mean_train_score']].sort_values(by = 'mean_test_score', \\\n",
    "                                                    ascending = False)\n",
    "scoresCV.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizing the Gradient Boosting Regressor with GridSearchCV (runtime ~14 min) I retrieved scores that I would not say are ideal. The difference between the mean test score and train score is very severe, therefore I chose one more method to try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=6, max_iter=20; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=6, max_iter=20; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=6, max_iter=20; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=6, max_iter=20; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=6, max_iter=20; total time=   0.5s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=6, max_iter=50; total time=   1.0s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=6, max_iter=50; total time=   1.1s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=6, max_iter=50; total time=   1.1s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=6, max_iter=50; total time=   0.9s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=6, max_iter=50; total time=   1.0s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=6, max_iter=100; total time=   1.6s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=6, max_iter=100; total time=   1.6s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=6, max_iter=100; total time=   1.8s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=10, max_iter=20; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=6, max_iter=100; total time=   1.7s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=10, max_iter=20; total time=   1.0s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=10, max_iter=20; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=6, max_iter=100; total time=   1.6s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=10, max_iter=20; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=10, max_iter=20; total time=   0.9s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=10, max_iter=50; total time=   1.0s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=10, max_iter=50; total time=   1.2s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=10, max_iter=50; total time=   1.4s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=10, max_iter=50; total time=   1.3s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=10, max_iter=50; total time=   1.3s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=10, max_iter=100; total time=   2.5s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=10, max_iter=100; total time=   2.3s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=10, max_iter=100; total time=   2.3s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=10, max_iter=100; total time=   2.2s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=None, max_iter=20; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=None, max_iter=20; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=None, max_iter=20; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=None, max_iter=20; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=10, max_iter=100; total time=   2.0s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=None, max_iter=20; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=None, max_iter=50; total time=   1.4s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=None, max_iter=50; total time=   1.5s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=None, max_iter=50; total time=   1.4s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=None, max_iter=50; total time=   1.5s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=None, max_iter=50; total time=   1.6s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=None, max_iter=100; total time=   2.5s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=None, max_iter=100; total time=   2.9s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=None, max_iter=100; total time=   3.1s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=6, max_iter=20; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=6, max_iter=20; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=None, max_iter=100; total time=   3.3s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=6, max_iter=20; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, loss=squared_error, max_depth=None, max_iter=100; total time=   2.4s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=6, max_iter=20; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=6, max_iter=20; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=6, max_iter=50; total time=   1.1s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=6, max_iter=50; total time=   1.1s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=6, max_iter=50; total time=   1.3s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=6, max_iter=50; total time=   1.0s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=6, max_iter=50; total time=   1.4s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=6, max_iter=100; total time=   2.0s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=6, max_iter=100; total time=   1.7s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=6, max_iter=100; total time=   2.2s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=10, max_iter=20; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=10, max_iter=20; total time=   0.9s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=6, max_iter=100; total time=   2.2s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=10, max_iter=20; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=6, max_iter=100; total time=   2.0s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=10, max_iter=20; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=10, max_iter=20; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=10, max_iter=50; total time=   1.4s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=10, max_iter=50; total time=   1.4s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=10, max_iter=50; total time=   1.6s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=10, max_iter=50; total time=   1.6s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=10, max_iter=50; total time=   1.3s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=10, max_iter=100; total time=   2.9s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=10, max_iter=100; total time=   3.2s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=10, max_iter=100; total time=   3.0s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=10, max_iter=100; total time=   3.0s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=None, max_iter=20; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=None, max_iter=20; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=None, max_iter=20; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=None, max_iter=20; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=None, max_iter=20; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=10, max_iter=100; total time=   2.4s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=None, max_iter=50; total time=   1.3s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=None, max_iter=50; total time=   1.5s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=None, max_iter=50; total time=   1.6s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=None, max_iter=50; total time=   1.7s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=None, max_iter=50; total time=   1.4s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=None, max_iter=100; total time=   2.7s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=None, max_iter=100; total time=   3.2s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=None, max_iter=100; total time=   2.7s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=6, max_iter=20; total time=   0.5s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=None, max_iter=100; total time=   3.0s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=6, max_iter=20; total time=   0.5s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=6, max_iter=20; total time=   0.5s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=6, max_iter=20; total time=   0.6s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=6, max_iter=20; total time=   0.5s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=6, max_iter=50; total time=   0.8s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=6, max_iter=50; total time=   1.2s\n",
      "[CV] END learning_rate=0.1, loss=absolute_error, max_depth=None, max_iter=100; total time=   3.0s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=6, max_iter=50; total time=   1.1s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=6, max_iter=50; total time=   0.9s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=6, max_iter=50; total time=   1.1s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=6, max_iter=100; total time=   1.7s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=6, max_iter=100; total time=   1.8s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=6, max_iter=100; total time=   1.7s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=10, max_iter=20; total time=   0.6s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=6, max_iter=100; total time=   1.6s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=10, max_iter=20; total time=   0.8s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=10, max_iter=20; total time=   0.6s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=10, max_iter=20; total time=   0.7s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=6, max_iter=100; total time=   1.6s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=10, max_iter=20; total time=   0.7s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=10, max_iter=50; total time=   1.0s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=10, max_iter=50; total time=   1.2s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=10, max_iter=50; total time=   1.3s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=10, max_iter=50; total time=   1.5s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=10, max_iter=50; total time=   1.0s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=10, max_iter=100; total time=   2.3s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=10, max_iter=100; total time=   1.7s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=10, max_iter=100; total time=   2.0s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=10, max_iter=100; total time=   2.4s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=None, max_iter=20; total time=   0.6s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=None, max_iter=20; total time=   0.7s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=None, max_iter=20; total time=   0.9s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=None, max_iter=20; total time=   0.6s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=None, max_iter=20; total time=   0.7s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=10, max_iter=100; total time=   2.0s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=None, max_iter=50; total time=   1.2s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=None, max_iter=50; total time=   1.5s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=None, max_iter=50; total time=   1.7s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=None, max_iter=50; total time=   1.3s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=None, max_iter=50; total time=   1.9s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=None, max_iter=100; total time=   3.0s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=None, max_iter=100; total time=   2.6s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=None, max_iter=100; total time=   3.0s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=6, max_iter=20; total time=   0.6s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=None, max_iter=100; total time=   3.2s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=6, max_iter=20; total time=   0.7s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=6, max_iter=20; total time=   0.6s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=6, max_iter=20; total time=   0.6s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=6, max_iter=20; total time=   0.7s\n",
      "[CV] END learning_rate=0.3, loss=squared_error, max_depth=None, max_iter=100; total time=   2.6s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=6, max_iter=50; total time=   1.1s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=6, max_iter=50; total time=   1.1s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=6, max_iter=50; total time=   1.1s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=6, max_iter=50; total time=   1.3s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=6, max_iter=50; total time=   1.2s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=6, max_iter=100; total time=   2.4s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=6, max_iter=100; total time=   2.4s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=6, max_iter=100; total time=   2.3s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=6, max_iter=100; total time=   2.1s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=10, max_iter=20; total time=   1.1s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=10, max_iter=20; total time=   0.9s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=10, max_iter=20; total time=   1.2s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=10, max_iter=20; total time=   0.9s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=10, max_iter=20; total time=   0.8s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=6, max_iter=100; total time=   2.7s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=10, max_iter=50; total time=   1.9s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=10, max_iter=50; total time=   2.1s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=10, max_iter=50; total time=   1.9s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=10, max_iter=50; total time=   2.1s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=10, max_iter=50; total time=   2.3s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=10, max_iter=100; total time=   3.7s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=10, max_iter=100; total time=   4.6s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=10, max_iter=100; total time=   4.2s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=None, max_iter=20; total time=   0.9s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=None, max_iter=20; total time=   1.2s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=10, max_iter=100; total time=   4.2s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=None, max_iter=20; total time=   0.8s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=None, max_iter=20; total time=   0.8s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=None, max_iter=20; total time=   1.0s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=10, max_iter=100; total time=   3.2s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=None, max_iter=50; total time=   1.7s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=None, max_iter=50; total time=   2.0s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=None, max_iter=50; total time=   1.8s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=None, max_iter=50; total time=   1.9s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=None, max_iter=50; total time=   1.9s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=None, max_iter=100; total time=   3.5s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=None, max_iter=100; total time=   3.3s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=None, max_iter=100; total time=   3.7s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=6, max_iter=20; total time=   0.7s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=6, max_iter=20; total time=   0.8s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=None, max_iter=100; total time=   3.4s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=6, max_iter=20; total time=   0.6s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=6, max_iter=20; total time=   0.6s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=6, max_iter=20; total time=   0.8s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=6, max_iter=50; total time=   1.1s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=6, max_iter=50; total time=   1.2s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=6, max_iter=50; total time=   1.5s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=6, max_iter=50; total time=   1.1s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=6, max_iter=50; total time=   1.2s\n",
      "[CV] END learning_rate=0.3, loss=absolute_error, max_depth=None, max_iter=100; total time=   3.9s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=6, max_iter=100; total time=   1.7s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=6, max_iter=100; total time=   1.8s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=6, max_iter=100; total time=   2.0s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=6, max_iter=100; total time=   2.1s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=10, max_iter=20; total time=   0.8s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=10, max_iter=20; total time=   0.7s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=6, max_iter=100; total time=   1.9s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=10, max_iter=20; total time=   0.9s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=10, max_iter=20; total time=   0.8s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=10, max_iter=20; total time=   1.0s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=10, max_iter=50; total time=   1.4s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=10, max_iter=50; total time=   1.6s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=10, max_iter=50; total time=   1.5s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=10, max_iter=50; total time=   1.3s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=10, max_iter=50; total time=   1.3s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=10, max_iter=100; total time=   2.4s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=10, max_iter=100; total time=   2.0s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=10, max_iter=100; total time=   2.3s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=None, max_iter=20; total time=   1.0s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=10, max_iter=100; total time=   2.1s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=None, max_iter=20; total time=   1.0s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=10, max_iter=100; total time=   1.9s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=None, max_iter=20; total time=   0.9s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=None, max_iter=20; total time=   0.9s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=None, max_iter=20; total time=   0.8s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=None, max_iter=50; total time=   1.5s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=None, max_iter=50; total time=   1.8s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=None, max_iter=50; total time=   1.9s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=None, max_iter=50; total time=   1.9s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=None, max_iter=50; total time=   1.5s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=None, max_iter=100; total time=   3.2s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=None, max_iter=100; total time=   3.7s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=None, max_iter=100; total time=   2.8s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=None, max_iter=100; total time=   4.0s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=6, max_iter=20; total time=   0.8s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=6, max_iter=20; total time=   0.7s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=6, max_iter=20; total time=   0.7s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=6, max_iter=20; total time=   0.6s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=6, max_iter=20; total time=   0.8s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=6, max_iter=50; total time=   1.2s\n",
      "[CV] END learning_rate=0.5, loss=squared_error, max_depth=None, max_iter=100; total time=   3.2s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=6, max_iter=50; total time=   1.3s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=6, max_iter=50; total time=   1.5s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=6, max_iter=50; total time=   1.3s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=6, max_iter=50; total time=   1.4s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=6, max_iter=100; total time=   2.2s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=6, max_iter=100; total time=   2.5s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=6, max_iter=100; total time=   2.4s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=6, max_iter=100; total time=   2.2s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=10, max_iter=20; total time=   0.9s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=10, max_iter=20; total time=   0.8s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=10, max_iter=20; total time=   1.0s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=10, max_iter=20; total time=   1.0s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=6, max_iter=100; total time=   2.7s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=10, max_iter=20; total time=   1.0s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=10, max_iter=50; total time=   1.6s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=10, max_iter=50; total time=   1.8s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=10, max_iter=50; total time=   2.3s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=10, max_iter=50; total time=   1.9s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=10, max_iter=50; total time=   1.6s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=10, max_iter=100; total time=   3.7s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=10, max_iter=100; total time=   3.5s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=10, max_iter=100; total time=   3.4s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=10, max_iter=100; total time=   3.9s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=None, max_iter=20; total time=   0.8s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=None, max_iter=20; total time=   0.8s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=None, max_iter=20; total time=   0.9s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=None, max_iter=20; total time=   1.2s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=None, max_iter=20; total time=   0.8s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=10, max_iter=100; total time=   3.0s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=None, max_iter=50; total time=   1.9s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=None, max_iter=50; total time=   1.5s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=None, max_iter=50; total time=   2.3s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=None, max_iter=50; total time=   2.0s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=None, max_iter=50; total time=   1.9s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=None, max_iter=100; total time=   3.3s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=None, max_iter=100; total time=   3.8s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=None, max_iter=100; total time=   3.3s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=None, max_iter=100; total time=   3.6s\n",
      "[CV] END learning_rate=0.5, loss=absolute_error, max_depth=None, max_iter=100; total time=   2.4s\n",
      "Best params, best score: 0.8268 {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 10, 'max_iter': 100}\n"
     ]
    }
   ],
   "source": [
    "parameters = {'max_depth':[6,10,None], 'loss':['squared_error','absolute_error'], \n",
    "              'max_iter':[20,50,100], 'learning_rate': [0.1,0.3,0.5]}\n",
    "nmodels = np.product([len(el) for el in parameters.values()])\n",
    "model = GridSearchCV(HistGradientBoostingRegressor(max_bins = 100), parameters, \n",
    "                     cv = KFold(n_splits=5, shuffle=True, random_state = 5), \\\n",
    "                     verbose = 2, n_jobs = 4, return_train_score=True)\n",
    "model.fit(reduced_spectra,log_tau.values.ravel())\n",
    "\n",
    "print('Best params, best score:', \"{:.4f}\".format(model.best_score_), \\\n",
    "      model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'squared_error'...</td>\n",
       "      <td>0.826839</td>\n",
       "      <td>0.016365</td>\n",
       "      <td>0.997716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'squared_error'...</td>\n",
       "      <td>0.826774</td>\n",
       "      <td>0.021346</td>\n",
       "      <td>0.997045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'squared_error'...</td>\n",
       "      <td>0.824408</td>\n",
       "      <td>0.016368</td>\n",
       "      <td>0.997903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'squared_error'...</td>\n",
       "      <td>0.823954</td>\n",
       "      <td>0.017155</td>\n",
       "      <td>0.987217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'squared_error'...</td>\n",
       "      <td>0.823155</td>\n",
       "      <td>0.020354</td>\n",
       "      <td>0.981962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              params  mean_test_score  \\\n",
       "5  {'learning_rate': 0.1, 'loss': 'squared_error'...         0.826839   \n",
       "2  {'learning_rate': 0.1, 'loss': 'squared_error'...         0.826774   \n",
       "8  {'learning_rate': 0.1, 'loss': 'squared_error'...         0.824408   \n",
       "4  {'learning_rate': 0.1, 'loss': 'squared_error'...         0.823954   \n",
       "1  {'learning_rate': 0.1, 'loss': 'squared_error'...         0.823155   \n",
       "\n",
       "   std_test_score  mean_train_score  \n",
       "5        0.016365          0.997716  \n",
       "2        0.021346          0.997045  \n",
       "8        0.016368          0.997903  \n",
       "4        0.017155          0.987217  \n",
       "1        0.020354          0.981962  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hist GBR scores \n",
    "\n",
    "scores = pd.DataFrame(model.cv_results_)\n",
    "scoresCV = scores[['params','mean_test_score','std_test_score','mean_train_score']].sort_values(by = 'mean_test_score', \\\n",
    "                                                    ascending = False)\n",
    "scoresCV.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scores between the GBR and HistGBR are almost 1:1, but the run time for HistGBR was only 1 min 54 sec, which is  x14 quicker than GBR. After discussing with my peers we agreed that the test score of 0.82 was a suitable result. Although the test scores are not ideal, we beliave that it is the best possible outcome given the constraints of the project."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
